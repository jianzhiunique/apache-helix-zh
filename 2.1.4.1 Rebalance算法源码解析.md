Helix本身提供了四种Rebalance的机制

- FULL_AUTO 对应AutoRebalancer
- SEMI_AUTO 对应SemiAutoRebalancer
- CUSTOMIZED 对应CustomRebalancer
- USER_DEFINED 对应Rebalancer接口或者AbstractRebalancer的用户实现类

除此之外，在Helix的源码中，还有两个类

- DelayedAutoRebalancer extends AbstractRebalancer
- MaintenanceRebalancer extends SemiAutoRebalancer



## Rebalancer接口

```
/**
 * Helix允许用户自己实现rebalancer
 * 所有集群上的改变都会调用rebalancer
 * 只需要为resource返回newIdealState就可以了
 */
public interface Rebalancer<T extends BaseControllerDataProvider> {
  void init(HelixManager manager);

  /**
   * 这个方法为resource的重平衡提供所有相关信息
   * 如果需要额外的信息，可以通过manager.getAccessor 来读取集群数据.
   * 这里允许用户来计算newIdealState，来支持特殊APP的需求
   * @param resourceName 要进行rb的resource
   * @param currentIdealState 当前理想状态
   * @param currentStateOutput 提供每个分区的当前状态以及正在进行中的状态转换         
   * @param clusterData 提供额外的方法来获取集群数据
   * @return
   */
   IdealState computeNewIdealState(String resourceName,
      IdealState currentIdealState, final CurrentStateOutput currentStateOutput,
      T clusterData);
}
```

## MappingCalculator接口

```
/**
 * 通过将IdealState转换为ResourceAssignment，扩展Rebalancer的功能 
 * WARNING: 这是一个内部接口，可能随着版本发布而改变
 */
public interface MappingCalculator<T extends BaseControllerDataProvider> {
  /**
   * 给定resource的理想状态和当前存活的实例节点，为每个分区的副本计算最佳的可能的状态分配
   * @param cache
   * @param idealState
   * @param resource
   * @param currentStateOutput 提供每个分区的当前状态以及正在进行中的状态转换    
   * @return
   */
  ResourceAssignment computeBestPossiblePartitionState(
      T cache, IdealState idealState, Resource resource, CurrentStateOutput currentStateOutput);
}
```

## RebalanceStrategy接口

```
//在AbstractRebalancer抽象类中实际没有用到，只是保存了一下
//在AbstractRebalancer抽象类的实现中，是会用到来计算分区分配的
public interface RebalanceStrategy<T extends BaseControllerDataProvider> {
  String DEFAULT_REBALANCE_STRATEGY = "DEFAULT"; //默认为DEFAULT

  /**
   * 为重平衡策略执行必要的初始化
   *
   * @param resourceName
   * @param partitions
   * @param states
   * @param maximumPerNode
   */
  void init(String resourceName, final List<String> partitions,
      final LinkedHashMap<String, Integer> states, int maximumPerNode);

  /**
   * 为给定的resource计算偏好list（preference lists）以及可选的分区状态映射
   *
   * @param liveNodes
   * @param currentMapping
   * @param allNodes
   * @return
   */
  ZNRecord computePartitionAssignment(final List<String> allNodes, final List<String> liveNodes,
      final Map<String, Map<String, String>> currentMapping,
      T clusterData);
}
```

## AbstractRebalancer抽象类

```
/**
 * 这是一个抽象的rebalancer，为Helix rebalancer定义了许多默认的行为，同时给出了一些公用的工具性方法
 */
public abstract class AbstractRebalancer<T extends BaseControllerDataProvider> implements Rebalancer<T>,
    MappingCalculator<T> {
  // 这些应该是final的，但是在init方法中被初始化，而不是在构造函数
  protected HelixManager _manager;
  protected RebalanceStrategy<T> _rebalanceStrategy;

  private static final Logger LOG = LoggerFactory.getLogger(AbstractRebalancer.class);

  @Override
  public void init(HelixManager manager) {
    this._manager = manager;
    this._rebalanceStrategy = null;
  }

//这里是Rebalancer接口的核心方法，并没有实现
  @Override
  public abstract IdealState computeNewIdealState(
      String resourceName, IdealState currentIdealState, CurrentStateOutput currentStateOutput,
      T clusterData);

  /**
   * 为所有分区计算最佳状态，这里是MappingCalculator接口
   * 这是一个默认实现，如果子类的需求不同，子类应重新实现
   *
   * @param cache
   * @param idealState
   * @param resource
   * @param currentStateOutput 提供每个分区的当前状态以及正在进行中的状态转换
   * @return 返回了ResourceAssignment
   */
  @Override
  public ResourceAssignment computeBestPossiblePartitionState(
      T cache, IdealState idealState, Resource resource,
      CurrentStateOutput currentStateOutput) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Processing resource:" + resource.getResourceName());
    }
    //状态模型名称
    String stateModelDefName = idealState.getStateModelDefRef();
    //从cache中获取状态模型定义
    StateModelDefinition stateModelDef = cache.getStateModelDef(stateModelDefName);
    //新建一个resource的分区分配
    ResourceAssignment partitionMapping = new ResourceAssignment(resource.getResourceName());
    //遍历所有分区
    for (Partition partition : resource.getPartitions()) {
    //获取分区被禁用的节点列表
      Set<String> disabledInstancesForPartition =
          cache.getDisabledInstancesForPartition(resource.getResourceName(), partition.toString());
          //获取偏好的列表，内部调用 1，传入了集群存活的节点
      List<String> preferenceList = getPreferenceList(partition, idealState,
          Collections.unmodifiableSet(cache.getLiveInstances().keySet()));
          //分区最佳状态计算，内部调用 2，
      Map<String, String> bestStateForPartition =
          computeBestPossibleStateForPartition(cache.getLiveInstances().keySet(), stateModelDef,
              preferenceList, currentStateOutput, disabledInstancesForPartition, idealState,
              cache.getClusterConfig(), partition);
      partitionMapping.addReplicaMap(partition, bestStateForPartition);
    }
    return partitionMapping;
  }
  
  //内部调用1，返回的是偏好节点列表，
  public static List<String> getPreferenceList(Partition partition, IdealState idealState,
      Set<String> eligibleInstances) {
      //获取分区的理想状态配置
    List<String> listField = idealState.getPreferenceList(partition.getPartitionName());

//配置不为空，size是1，并且配置是ANY_LIVEINSTANCE的话，对合格的节点排序后返回，否则，返回配置
    if (listField != null && listField.size() == 1
        && IdealState.IdealStateConstants.ANY_LIVEINSTANCE.toString().equals(listField.get(0))) {
      List<String> prefList = new ArrayList<String>(eligibleInstances);
      Collections.sort(prefList);
      return prefList;
    } else {
      return listField;
    }
  }
  
  //内部调用2，为分区计算最佳状态
  //参数：存活节点，状态模型定义，偏好列表，当前状态，分区被禁用的节点，理想状态，集群配置，分区
  protected Map<String, String> computeBestPossibleStateForPartition(Set<String> liveInstances,
      StateModelDefinition stateModelDef, List<String> preferenceList,
      CurrentStateOutput currentStateOutput, Set<String> disabledInstancesForPartition,
      IdealState idealState, ClusterConfig clusterConfig, Partition partition) {

//通过当前的currentStateOutput获取到当前的状态map
    Map<String, String> currentStateMap =
        currentStateOutput.getCurrentStateMap(idealState.getResourceName(), partition);

    if (currentStateMap == null) {
      currentStateMap = Collections.emptyMap();
    }

    // (1) 如果分区从理想状态IS移除或者IS被删除，不管节点是否是禁用的，转移到DROPPED状态
    //内部调用 3
    if (preferenceList == null) {
      return computeBestPossibleMapForDroppedResource(currentStateMap);
    }

    // (2) 如果资源被禁用了，如果它不在ERROR状态，转换为初始状态如OFFLINE
    //内部调用4
    if (!idealState.isEnabled()) {
      return computeBestPossibleMapForDisabledResource(currentStateMap, stateModelDef);
    }

    //否则进行计算，内部调用5
    return computeBestPossibleMap(preferenceList, stateModelDef, currentStateMap, liveInstances,
        disabledInstancesForPartition);
  }
  
  //内部调用3，将当前状态map中设置为DROPPED
  protected Map<String, String> computeBestPossibleMapForDroppedResource(Map<String, String> currentStateMap) {
    Map<String, String> bestPossibleStateMap = new HashMap<String, String>();
    for (String instance : currentStateMap.keySet()) {
      bestPossibleStateMap.put(instance, HelixDefinedState.DROPPED.toString());
    }
    return bestPossibleStateMap;
  }
  
  //内部调用4
  protected Map<String, String> computeBestPossibleMapForDisabledResource(Map<String, String> currentStateMap
      , StateModelDefinition stateModelDef) {
    Map<String, String> bestPossibleStateMap = new HashMap<String, String>();
    for (String instance : currentStateMap.keySet()) {
      if (!HelixDefinedState.ERROR.name().equals(currentStateMap.get(instance))) {
        bestPossibleStateMap.put(instance, stateModelDef.getInitialState());
      }
    }
    return bestPossibleStateMap;
  }
  
  //内部调用 5
  /**
   * 这个方法为分区生成instance->state映射。基于他的偏好preferenceList和状态模型定义
   * preferenceList在不同的rebalancer可能会不同，比如DelayedAutoRebalancer
   * 这个方法也确保一些边界情况，像是disabled的节点或者ERROR的节点能被正确处理
   * currentStateMap必须是非空的
   */
  protected Map<String, String> computeBestPossibleMap(List<String> preferenceList, StateModelDefinition stateModelDef,
      Map<String, String> currentStateMap, Set<String> liveInstances, Set<String> disabledInstancesForPartition) {

    Map<String, String> bestPossibleStateMap = new HashMap<>();

    // (1) 节点有当前状态，但是不在偏好列表中，不管他是否被禁用，都丢弃
    for (String instance : currentStateMap.keySet()) {
      if (!preferenceList.contains(instance)) {
        bestPossibleStateMap.put(instance, HelixDefinedState.DROPPED.name());
      }
    }

    // (2) 如果节点被禁用，并且在偏好列表中，设置为初始状态；当心条件判断
    for (String instance : preferenceList) {
      if (disabledInstancesForPartition.contains(instance)) {
        if (currentStateMap.containsKey(instance)) {
        //偏好节点在当前状态里，并且不是ERROR状态，变为初始状态
          if (!currentStateMap.get(instance).equals(HelixDefinedState.ERROR.name())) {
            bestPossibleStateMap.put(instance, stateModelDef.getInitialState());
          }
        } else {
        //如果偏好中的不在当前状态，也要添加，并设置为初始状态
          if (liveInstances.contains(instance)) {
            bestPossibleStateMap.put(instance, stateModelDef.getInitialState());
          }
        }
      }
    }

    // (3) 为节点分配正常的状态
    // 当选择类似于MASTER的高级状态时，优先从已经在二级状态如SLAVE中选择；而不是更低级的状态
    // 因为二级状态的将使用更少的时间来转换为高级状态，这样可能会对app的可用性造成最小的影响
    // 为了实现，基于CurrentState对preferenceList进行排序；把高级状态和二级状态视为同一优先级；
    // 并且依赖Collections.sort() 排序是稳定的.
    List<String> statesPriorityList = stateModelDef.getStatesPriorityList();
    Set<String> assigned = new HashSet<>();
    Set<String> liveAndEnabled = new HashSet<>(liveInstances);
    //存活的并且可用的节点
    liveAndEnabled.removeAll(disabledInstancesForPartition);

    for (String state : statesPriorityList) {
      // 使用特定的排序的preferenceList 来选择顶级状态的节点
      if (state.equals(statesPriorityList.get(0))) {
        List<String> preferenceListForTopState = new ArrayList<>(preferenceList);
        
        //用的是这个比较器 TopStatePreferenceListComparator
        
        Collections.sort(preferenceListForTopState,
            new TopStatePreferenceListComparator(currentStateMap, stateModelDef));
        preferenceList = preferenceListForTopState;
      }

      //处于某种状态的副本数量，内部调用6
      int stateCount =
          getStateCount(state, stateModelDef, liveAndEnabled.size(), preferenceList.size());
      //遍历偏好列表
      for (String instance : preferenceList) {
        if (stateCount <= 0) {
          break;
        }
        //分配结果里不含该节点，并且节点还存活和可用的话
        if (!assigned.contains(instance) && liveAndEnabled.contains(instance)) {
        //当前是ERROR状态的节点，依然是ERROR
          if (HelixDefinedState.ERROR.toString().equals(currentStateMap.get(instance))) {
            bestPossibleStateMap.put(instance, HelixDefinedState.ERROR.toString());
          } else {
          //否则设置为正确的状态
            bestPossibleStateMap.put(instance, state);
            stateCount--;
          }
          //将节点加入已分配节点，下次循环不再使用
          assigned.add(instance);
        }
      }
    }

    return bestPossibleStateMap;
  }
  
  //内部调用6
  public static int getStateCount(String state, StateModelDefinition stateModelDef, int liveAndEnabledSize,
      int preferenceListSize) {
    String num = stateModelDef.getNumInstancesPerState(state);
    int stateCount = -1;
    if ("N".equals(num)) {
      stateCount = liveAndEnabledSize;
    } else if ("R".equals(num)) {
      stateCount = preferenceListSize;
    } else {
      try {
        stateCount = Integer.parseInt(num);
      } catch (Exception e) {
        LOG.error("Invalid count for state:" + state + " ,count=" + num);
      }
    }

    return stateCount;
  }
  
  //然后其他的方法都是额外的工具类方法了
  /**
   * 查找resource的缓存过的理想mapping，如果存在，不再进行再次计算
   * 缓存清理时机：在ResourceControllerDataProvider中，如果集群状态有任何变化都会导致潜在的理想状态变化
   * 这会避免AutoRebalanceStrategy中的flip-flop问题，同时也能改善性能，因为不需要每次都计算IS
   */
  protected IdealState getCachedIdealState(String resourceName, ResourceControllerDataProvider clusterData) {
    ZNRecord cachedIdealMapping = clusterData.getCachedIdealMapping(resourceName);
    if (cachedIdealMapping != null) {
      return new IdealState(cachedIdealMapping);
    }

    return null;
  }

//当前的mapping
  protected Map<String, Map<String, String>> currentMapping(CurrentStateOutput currentStateOutput,
      String resourceName, List<String> partitions, Map<String, Integer> stateCountMap) {

    Map<String, Map<String, String>> map = new HashMap<>();

    for (String partition : partitions) {
      Map<String, String> curStateMap =
          currentStateOutput.getCurrentStateMap(resourceName, new Partition(partition));
      map.put(partition, new HashMap<String, String>());
      for (String node : curStateMap.keySet()) {
        String state = curStateMap.get(node);
        map.get(partition).put(node, state);
      }

      Map<String, String> pendingStateMap =
          currentStateOutput.getPendingStateMap(resourceName, new Partition(partition));
      for (String node : pendingStateMap.keySet()) {
        String state = pendingStateMap.get(node);
        map.get(partition).put(node, state);
      }
    }
    return map;
  }

//获取RB策略
  protected RebalanceStrategy<T> getRebalanceStrategy(
      String rebalanceStrategyName, List<String> partitions, String resourceName,
      LinkedHashMap<String, Integer> stateCountMap, int maxPartition) {
    RebalanceStrategy rebalanceStrategy;
    if (rebalanceStrategyName == null || rebalanceStrategyName
        .equalsIgnoreCase(RebalanceStrategy.DEFAULT_REBALANCE_STRATEGY)) {
      rebalanceStrategy =
          new AutoRebalanceStrategy(resourceName, partitions, stateCountMap, maxPartition);
    } else {
      try {
        rebalanceStrategy = RebalanceStrategy.class
            .cast(HelixUtil.loadClass(getClass(), rebalanceStrategyName).newInstance());
        rebalanceStrategy.init(resourceName, partitions, stateCountMap, maxPartition);
      } catch (ClassNotFoundException ex) {
        throw new HelixException(
            "Exception while invoking custom rebalance strategy class: " + rebalanceStrategyName,
            ex);
      } catch (InstantiationException ex) {
        throw new HelixException(
            "Exception while invoking custom rebalance strategy class: " + rebalanceStrategyName,
            ex);
      } catch (IllegalAccessException ex) {
        throw new HelixException(
            "Exception while invoking custom rebalance strategy class: " + rebalanceStrategyName,
            ex);
      }
    }

    return rebalanceStrategy;
  }

 
}
```

#### PreferenceListNodeComparator

```
/**
 * Sorter for nodes that sorts according to the CurrentState of the partition, based on the state priority defined
 * in the state model definition.
 * If the CurrentState doesn't exist, treat it as having lowest priority(Integer.MAX_VALUE).
 */
protected static class PreferenceListNodeComparator implements Comparator<String> {
  protected final Map<String, String> _currentStateMap;
  protected final StateModelDefinition _stateModelDef;
  protected final List<String> _preferenceList;

  public PreferenceListNodeComparator(Map<String, String> currentStateMap,
      StateModelDefinition stateModelDef, List<String> preferenceList) {
    _currentStateMap = currentStateMap;
    _stateModelDef = stateModelDef;
    _preferenceList = preferenceList;
  }

  @Override
  public int compare(String ins1, String ins2) {
    // condition :
    // 1. both in preference list, keep the order in preference list
    // 2. one them in preference list, the one in preference list has higher priority
    // 3. none of them in preference list, sort by state.
    if (_preferenceList.contains(ins1) && _preferenceList.contains(ins2)) {
      return _preferenceList.indexOf(ins1) - _preferenceList.indexOf(ins2);
    } else if (_preferenceList.contains(ins1)) {
      return -1;
    } else if (_preferenceList.contains(ins2)) {
      return 1;
    }
    Integer p1 = Integer.MAX_VALUE;
    Integer p2 = Integer.MAX_VALUE;

    Map<String, Integer> statesPriorityMap = _stateModelDef.getStatePriorityMap();
    String state1 = _currentStateMap.get(ins1);
    String state2 = _currentStateMap.get(ins2);
    if (state1 != null && statesPriorityMap.containsKey(state1)) {
      p1 = statesPriorityMap.get(state1);
    }
    if (state2 != null && statesPriorityMap.containsKey(state2)) {
      p2 = statesPriorityMap.get(state2);
    }

    return p1.compareTo(p2);
  }
}
```

## FULL_AUTO - AutoRebalancer

```
/**
 * 这是full automatic对应的Rebalancer。他会计算resource的理想状态，自动调整集群节点的增加和删除；
 * 这包括计算一个新的偏好列表preference list，以及基于这个列表决定分区到节点和状态的mapping
 * 输入是当前的节点上的分配，以及现存的实例偏好，如果有的话
 * 输出是preference list和mapping，基于preference list
 * 例如分区p有一个副本replica在节点k上，状态是s
 */
public class AutoRebalancer extends AbstractRebalancer<ResourceControllerDataProvider> {
  private static final Logger LOG = LoggerFactory.getLogger(AutoRebalancer.class);

  @Override
  //AbstractRebalancer抽象类中没有实现的Rebalancer的接口，在这里实现了
  public IdealState computeNewIdealState(String resourceName,
      IdealState currentIdealState, CurrentStateOutput currentStateOutput,
      ResourceControllerDataProvider clusterData) {

//首先是检测了是否有cache，上面有提到cache的由来
    IdealState cachedIdealState = getCachedIdealState(resourceName, clusterData);
    if (cachedIdealState != null) {
      LOG.debug("Use cached IdealState for " + resourceName);
      return cachedIdealState;
    }

    LOG.info("Computing IdealState for " + resourceName);
    //分区列表
    List<String> partitions = new ArrayList<>(currentIdealState.getPartitionSet());
    //状态机名称
    String stateModelName = currentIdealState.getStateModelDefRef();
    //状态模型定义 ResourceControllerDataProvider上的
    StateModelDefinition stateModelDef = clusterData.getStateModelDef(stateModelName);
    if (stateModelDef == null) {
      LOG.error("State Model Definition null for resource: " + resourceName);
      throw new HelixException("State Model Definition null for resource: " + resourceName);
    }
    //当前集群的存活节点
    Map<String, LiveInstance> liveInstance = clusterData.getLiveInstances();
    //为resource确定副本数
    //首先会从IS的getReplicas方法，获取resource下的每个分区的副本数
    //SEMI_AUTO下，如果没有配置list，返回0；否则获取的是配置的list中第一个分区设置的副本数
    //CUSTOMIZED下，如果没有配置list，返回0；否则获取的是配置的map中第一个分区设置的副本数
    //其他情况IS的getReplicas返回0
    //如果返回不是整数，而是ANY_LIVEINSTANCE，那么使用存活的节点数
    //否则返回0
    int replicas = currentIdealState.getReplicaCount(liveInstance.size());
    
    //这个按照state的优先级返回一个有顺序的state->count的map
    //检查state的配置，N=存活的节点数；R=根据存活的节点动态变化；用户的设置，否则-1
    LinkedHashMap<String, Integer> stateCountMap = stateModelDef
        .getStateCountMap(liveInstance.size(), replicas);
    //存活节点名称
    List<String> liveNodes = new ArrayList<>(liveInstance.keySet());
    //所有节点名称
    List<String> allNodes = new ArrayList<>(clusterData.getAllInstances());
    // 所有节点。去除禁用的节点，包括存活+DEAD
    allNodes.removeAll(clusterData.getDisabledInstances());
    // 存活节点。去除存活节点中的禁用的节点
    liveNodes.retainAll(allNodes);

    //当前的mapping
    Map<String, Map<String, String>> currentMapping =
        currentMapping(currentStateOutput, resourceName, partitions, stateCountMap);

    // 如果节点上打了resource的tag，那么仅使用这些打了tag的节点
    Set<String> taggedNodes = new HashSet<String>();
    Set<String> taggedLiveNodes = new HashSet<String>();
    //从IS上获取INSTANCE_GROUP_TAG配置，如果设置了这个
    if (currentIdealState.getInstanceGroupTag() != null) {
    //遍历所有节点，找出包含这个tag的节点，把它添加到打tag的节点列表，并且进行存活检查
      for (String instanceName : allNodes) {
        if (clusterData.getInstanceConfigMap().get(instanceName)
            .containsTag(currentIdealState.getInstanceGroupTag())) {
          taggedNodes.add(instanceName);
          if (liveInstance.containsKey(instanceName)) {
            taggedLiveNodes.add(instanceName);
          }
        }
      }
      //如果可以按照tag的逻辑匹配到节点
      if (!taggedLiveNodes.isEmpty()) {
        // live nodes exist that have this tag
        if (LOG.isInfoEnabled()) {
          LOG.info("found the following participants with tag "
              + currentIdealState.getInstanceGroupTag() + " for " + resourceName + ": "
              + taggedLiveNodes);
        }
      } else if (taggedNodes.isEmpty()) {
        //如果不能按照tag找到任何节点，但资源配置了tag，记录日志
        //换句话说，没有节点打了这个tag，可能是忘记打了
        // no live nodes and no configured nodes have this tag
        LOG.warn("Resource " + resourceName + " has tag " + currentIdealState.getInstanceGroupTag()
            + " but no configured participants have this tag");
      } else {
        //否则就是节点上打tag这个做了，没有遗忘，但是没有存活的节点可以使用
        // configured nodes have this tag, but no live nodes have this tag
        LOG.warn("Resource " + resourceName + " has tag " + currentIdealState.getInstanceGroupTag()
            + " but no live participants have this tag");
      }
      allNodes = new ArrayList<>(taggedNodes);
      liveNodes = new ArrayList<>(taggedLiveNodes);
    }

    //排序以应对一致性偏好的分配
    Collections.sort(allNodes);
    Collections.sort(liveNodes);

    //获取节点上可以运行的最大分区数
    int maxPartition = currentIdealState.getMaxPartitionsPerInstance();
    //获取重平衡策略
    _rebalanceStrategy =
        getRebalanceStrategy(currentIdealState.getRebalanceStrategy(), partitions, resourceName, stateCountMap, maxPartition);
    //使用重平衡策略来计算分区分配，也就是mapping，所以这里肯定设计重平衡接口的实现类了，后面继再看
    ZNRecord newMapping = _rebalanceStrategy
        .computePartitionAssignment(allNodes, liveNodes, currentMapping, clusterData);

    if (LOG.isDebugEnabled()) {
      LOG.debug("currentMapping: " + currentMapping);
      LOG.debug("stateCountMap: " + stateCountMap);
      LOG.debug("liveNodes: " + liveNodes);
      LOG.debug("allNodes: " + allNodes);
      LOG.debug("maxPartition: " + maxPartition);
      LOG.debug("newMapping: " + newMapping);
    }
    //新的理想状态
    IdealState newIdealState = new IdealState(resourceName);
    //复制以前的配置    newIdealState.getRecord().setSimpleFields(
    currentIdealState.getRecord().getSimpleFields());
    //设置重平衡模式为FULL_AUTO
    newIdealState.setRebalanceMode(RebalanceMode.FULL_AUTO);
    //设置list字段原来的值，把新的mapping弄进去
    newIdealState.getRecord().setListFields(newMapping.getListFields());

    return newIdealState;
  }
}

//看起来AutoRebalancer就是自动确定了分区分配，failover之类的跟抽象类一样
```

## SEMI_AUTO - SemiAutoRebalancer

```
/**
 * 这是semi-automatic模式的rebalancer. 它的职责是根据预先定义的preference list来给出理想状态map
 * 输入是optional的当前的分配方案，以及必要的已经存在的节点的配置
 * 输出是基于preference list的mapping，比如分区p在节点k上有一个副本replica，状态是s
 * 
 * 注意：因为SemiAutoRebalancer被Resource controller和Workflow controller用到了，
 * 所以我们需要使用模板template作为data provider 类型
 */
public class SemiAutoRebalancer<T extends BaseControllerDataProvider>
    extends AbstractRebalancer<T> {

  @Override
  public IdealState computeNewIdealState(String resourceName, IdealState currentIdealState,
      CurrentStateOutput currentStateOutput, T clusterData) {
      //这里就是返回了currentIdealState
    return currentIdealState;
  }
}
```

## CUSTOMIZED - CustomRebalancer

```
/**
 * 这是custom 模式下的Rebalancer. 它的职责是检查现有的mapping与当前存活的实例，然后根据需要把分区的状态标记为dropped或者erroneous
 * 输入是当前的分配方案以及一些必要的节点配置
 * 输出是一个基于preference list的验证过的mapping
 * 例如分区p在节点k上有一个副本，状态为s, s可能是dropped 或者 error
 */
public class CustomRebalancer extends AbstractRebalancer<ResourceControllerDataProvider> {
  private static final Logger LOG = LoggerFactory.getLogger(CustomRebalancer.class);

  //这里跟SEMI_AUTO一样，都是返回配置
  @Override
  public IdealState computeNewIdealState(String resourceName, IdealState currentIdealState,
      CurrentStateOutput currentStateOutput, ResourceControllerDataProvider clusterData) {
    return currentIdealState;
  }

  @Override
  //这里重写了AbstractRebalancer为分区确定state的方法
  //说明这种模式下跟AbstractRebalancer的默认行为不一样
  public ResourceAssignment computeBestPossiblePartitionState(ResourceControllerDataProvider cache,
      IdealState idealState, Resource resource, CurrentStateOutput currentStateOutput) {
    // 首先还是看cache是否存在，如果存在就不用重复计算了
    // cache会被清理，ResourceControllerDataProvider会在集群状态有任何变化的时候去过期cache，因为任何集群方面的变化都可能会影响到BestPossible state.
    ResourceAssignment partitionMapping =
        cache.getCachedResourceAssignment(resource.getResourceName());
    if (partitionMapping != null) {
      return partitionMapping;
    }

    LOG.info("Computing BestPossibleMapping for " + resource.getResourceName());

    String stateModelDefName = idealState.getStateModelDefRef();
    //同样还是拿到resource的状态模型定义
    StateModelDefinition stateModelDef = cache.getStateModelDef(stateModelDefName);
    // 新的ResourceAssignment，处理后会返回它
    partitionMapping = new ResourceAssignment(resource.getResourceName());
    //遍历resource的每个分区
    for (Partition partition : resource.getPartitions()) {
    
      //当前分区的状态map，given (resource, partition), returns (instance->currentState) map
      //CurrentStateOutput存了当前的状态以及正在处理的消息，可以理解为toState and fromState正在转化中的那些
      Map<String, String> currentStateMap =
          currentStateOutput.getCurrentStateMap(resource.getResourceName(), partition);
      
      //被禁用的节点，是通过ResourceControllerDataProvider取的
      Set<String> disabledInstancesForPartition =
          cache.getDisabledInstancesForPartition(resource.getResourceName(), partition.toString());
      
      //获取当前分区的当前mapping
      //IS里仅仅是当前的分区mapping，是副本所在的节点->state的映射
      Map<String, String> idealStateMap =
          idealState.getInstanceStateMap(partition.getPartitionName());
      
      //使用computeCustomizedBestStateForPartition来获得最佳状态
      //默认行为是按照节点自动计算，所以这里是关键
      
      Map<String, String> bestStateForPartition =
          computeCustomizedBestStateForPartition(cache, stateModelDef, idealStateMap,
              currentStateMap, disabledInstancesForPartition, idealState.isEnabled());
      partitionMapping.addReplicaMap(partition, bestStateForPartition);
    }
    
    //设置缓存
    cache.setCachedResourceAssignment(resource.getResourceName(), partitionMapping);
    if (LOG.isDebugEnabled()) {
      LOG.debug(String.format("Processing resource: %s", resource.getResourceName()));
      LOG.debug(String.format("Final Mapping of resource : %s", partitionMapping.toString()));
    }
    return partitionMapping;
  }

  /**
   * compute best state for resource in CUSTOMIZED ideal state mode
   * CUSTOMIZED模式下为resource计算最佳state
   * @param cache ResourceControllerDataProvider
   * @param stateModelDef StateModelDefinition
   * @param idealStateMap IS的当前mapping
   * @param currentStateMap 当前状态mapping
   * @param disabledInstancesForPartition 被禁用的节点
   * @param isResourceEnabled resource是否被启用
   * @return
   */
  private Map<String, String> computeCustomizedBestStateForPartition(
      ResourceControllerDataProvider cache, StateModelDefinition stateModelDef,
      Map<String, String> idealStateMap, Map<String, String> currentStateMap,
      Set<String> disabledInstancesForPartition, boolean isResourceEnabled) {
     
    //这是要返回的结果
    Map<String, String> instanceStateMap = new HashMap<>();

    //如果理想状态被删除，idealStateMap 会是 null/empty，丢弃所有资源
    if (currentStateMap != null) {
      //当前状态对应的节点，遍历
      for (String instance : currentStateMap.keySet()) {
        //如果理想状态是空或者理想状态里不包含此节点，并且此节点对此分区没有被禁用，切换为DROPPED
        if ((idealStateMap == null || !idealStateMap.containsKey(instance))
            && !disabledInstancesForPartition.contains(instance)) {
          // 如果是丢弃状态，不管是不是被禁用的，都丢弃DROPPED
          instanceStateMap.put(instance, HelixDefinedState.DROPPED.toString());
        } else if ((currentStateMap.get(instance) == null || !currentStateMap.get(instance).equals(HelixDefinedState.ERROR.name()))
            && (!isResourceEnabled || disabledInstancesForPartition.contains(instance))) {
          //否则，如果节点的当前状态为空
          //或者节点上副本的状态为error
          //并且资源是禁用的，或者分区这个节点没有被禁用
          //即如果禁用了，并且不处于ERROR状态，转换到初始状态，如OFFLINE
          instanceStateMap.put(instance, stateModelDef.getInitialState());
        }
      }
    }

    //如果理想状态被删除了，直接返回上面的结果了
    if (idealStateMap == null) {
      return instanceStateMap;
    }

    //获取到存活的节点
    Map<String, LiveInstance> liveInstancesMap = cache.getLiveInstances();
    //遍历理想状态中的节点
    for (String instance : idealStateMap.keySet()) {
      // 有当前mapping，并且当前状态不是ERROR
      boolean notInErrorState = currentStateMap != null
          && !HelixDefinedState.ERROR.toString().equals(currentStateMap.get(instance));
      // 节点是否被禁用，或者资源是否被禁用
      boolean enabled = !disabledInstancesForPartition.contains(instance) && isResourceEnabled;

      //如果节点不存活，实例的mapping将不会展示在BestPossibleMapping和ExternalView中
      if (liveInstancesMap.containsKey(instance) && notInErrorState) {
        if (enabled) {
          instanceStateMap.put(instance, idealStateMap.get(instance));
        } else {
          // if disabled, put it in initial state
          instanceStateMap.put(instance, stateModelDef.getInitialState());
        }
      }
    }

    return instanceStateMap;
  }
}

//与AbstractRebalancer的不同是，AbstractRebalancer会有helix自动计算出mapping
//而CUSTOMIZED模式下，这个mapping是由APP来决定的
//computeBestPossiblePartitionState是MappingCalculator的方法，所以要看一下它的实现类以及他是在哪里被调用的
//它的实现类有AbstractRebalancer，CustomRebalancer，DelayedAutoRebalancer，DeprecatedTaskRebalancer（废弃），JobRebalancer，TaskRebalancer，WorkflowRebalancer
//task框架中的暂时不看，然后定位到BestPossibleStateCalcStage这个类

```

## BestPossibleStateCalcStage

```
/**
 * Logically independent unit in processing callbacks for cluster changes
 * 逻辑独立单元，在集群改变的时候，处理回调
 */
public interface Stage {
  void init(StageContext context);
  void release();
  void preProcess();
  void postProcess();
  String getStageName();

  /**
   * Actual callback processing logic
   * 实际callback逻辑
   * @param event
   * @throws Exception
   */
  public void process(ClusterEvent event) throws Exception;
}

// AbstractBaseStage implements Stage
// 但仅仅实现了getStageName，以及增加了两个方法，其他方法的实现是空方法
  public static <T> Future asyncExecute(ExecutorService service, Callable<T> task) {
    if (service != null) {
      return service.submit(task);
    }
    return null;
  }

  protected DedupEventProcessor<String, Runnable> getAsyncWorkerFromClusterEvent(ClusterEvent event,
      AsyncWorkerType workerType) {
    Map<AsyncWorkerType, DedupEventProcessor<String, Runnable>> workerPool =
        event.getAttribute(AttributeName.AsyncFIFOWorkerPool.name());
    if (workerPool != null) {
      if (workerPool.containsKey(workerType)) {
        return workerPool.get(workerType);
      }
    }
    return null;
  }
  
  
BestPossibleStateCalcStage extends AbstractBaseStage是一个比较完整的实现类了，
process() -> compute -> updateRebalanceStatus 
                     -> validateOfflineInstancesLimit 
                     -> computeResourceBestPossibleState -> 
             
computeResourceBestPossibleState 
-> checkBestPossibleStateCalculation
-> getRebalancer
-> getMappingCalculator

先看看BestPossibleStateCalcStage是在哪用的

1. GenericHelixController，rebalancePipeline.addStage(new BestPossibleStateCalcStage());
2. ClusterExternalViewVerifier，deprecated, please use BestPossibleExternalViewVerifier
3. ClusterStateVerifier，deprecated, please use dedicated verifier classes, such as BestPossibleExternalViewVerifier, etc, in tools.ClusterVerifiers.
4. BestPossibleExternalViewVerifier 这个看起来是在工具包里面命令行手动调用的逻辑
/* verifier that the ExternalViews of given resources (or all resources in the cluster) match its best possible mapping states. */
public class BestPossibleExternalViewVerifier extends ZkHelixClusterVerifier {

重点可能在控制器的逻辑里

/**
 * Cluster Controllers main goal is to keep the cluster state as close as possible to Ideal State.
 * It does this by listening to changes in cluster state and scheduling new tasks to get cluster
 * state to best possible ideal state. Every instance of this class can control can control only one
 * cluster Get all the partitions use IdealState, CurrentState and Messages <br>
 * foreach partition <br>
 * 1. get the (instance,state) from IdealState, CurrentState and PendingMessages <br>
 * 2. compute best possible state (instance,state) pair. This needs previous step data and state
 * model constraints <br>
 * 3. compute the messages/tasks needed to move to 1 to 2 <br>
 * 4. select the messages that can be sent, needs messages and state model constraints <br>
 * 5. send messages
 */
public class GenericHelixController implements IdealStateChangeListener,
    LiveInstanceChangeListener, MessageListener, CurrentStateChangeListener,
    ControllerChangeListener, InstanceConfigChangeListener, ResourceConfigChangeListener,
    ClusterConfigChangeListener {
    
1. GenericHelixController() -> createDefaultRegistry() -> rebalancePipeline.addStage(new BestPossibleStateCalcStage());
2. registry.register(ClusterEventType.LiveInstanceChange, dataRefresh, autoExitMaintenancePipeline, liveInstancePipeline, dataPreprocess, externalViewPipeline, rebalancePipeline);
3. handleEvent()
if (dataProvider instanceof ResourceControllerDataProvider) {
      pipelines = _registry
          .getPipelinesForEvent(event.getEventType());
for (Pipeline pipeline : pipelines) {
      event.addAttribute(AttributeName.PipelineType.name(), pipeline.getPipelineType());
      try {
        pipeline.handle(event);
        pipeline.finish();
4.for (Stage stage : _stages) {
      long startTime = System.currentTimeMillis();
      stage.preProcess();
      stage.process(event);
      stage.postProcess();

    

ZKHelixManager中会使用GenericHelixController，
  public void connect() throws Exception {
    switch (_instanceType) {
    case CONTROLLER:
    case CONTROLLER_PARTICIPANT:
      if (_controller == null) {
        _controller = new GenericHelixController(_clusterName, _enabledPipelineTypes);


```

#### 用户自定义的时机？

helix文档中说到：Helix提供了第三种模式，称为CUSTOMIZED，其中应用程序控制每个副本的位置*和*状态。应用程序需要实现一个回调接口，当集群状态改变时，Helix会调用该接口。在此回调中，应用程序可以重新计算理想状态。然后，Helix将发出适当的transitions，以使*Idealstate*和*Currentstate*收敛。

但并没有说是实现哪个接口，这相当费解

理论上讲，应该不是让用户直接修改GenericHelixController的pipeline