Helix本身提供了四种Rebalance的机制

- FULL_AUTO 对应AutoRebalancer
- SEMI_AUTO 对应SemiAutoRebalancer
- CUSTOMIZED 对应CustomRebalancer
- USER_DEFINED 对应Rebalancer接口或者AbstractRebalancer的用户实现类

除此之外，在Helix的源码中，还有两个类

- DelayedAutoRebalancer extends AbstractRebalancer
- MaintenanceRebalancer extends SemiAutoRebalancer



## Rebalancer接口

```
/**
 * Helix允许用户自己实现rebalancer
 * 所有集群上的改变都会调用rebalancer
 * 只需要为resource返回newIdealState就可以了
 */
public interface Rebalancer<T extends BaseControllerDataProvider> {
  void init(HelixManager manager);

  /**
   * 这个方法为resource的重平衡提供所有相关信息
   * 如果需要额外的信息，可以通过manager.getAccessor 来读取集群数据.
   * 这里允许用户来计算newIdealState，来支持特殊APP的需求
   * @param resourceName 要进行rb的resource
   * @param currentIdealState 当前理想状态
   * @param currentStateOutput 提供每个分区的当前状态以及正在进行中的状态转换         
   * @param clusterData 提供额外的方法来获取集群数据
   * @return
   */
   IdealState computeNewIdealState(String resourceName,
      IdealState currentIdealState, final CurrentStateOutput currentStateOutput,
      T clusterData);
}
```

## MappingCalculator接口

```
/**
 * 通过将IdealState转换为ResourceAssignment，扩展Rebalancer的功能 
 * WARNING: 这是一个内部接口，可能随着版本发布而改变
 */
public interface MappingCalculator<T extends BaseControllerDataProvider> {
  /**
   * 给定resource的理想状态和当前存活的实例节点，为每个分区的副本计算最佳的可能的状态分配
   * @param cache
   * @param idealState
   * @param resource
   * @param currentStateOutput 提供每个分区的当前状态以及正在进行中的状态转换    
   * @return
   */
  ResourceAssignment computeBestPossiblePartitionState(
      T cache, IdealState idealState, Resource resource, CurrentStateOutput currentStateOutput);
}
```

## RebalanceStrategy接口

```
//在AbstractRebalancer抽象类中实际没有用到，只是保存了一下
//在AbstractRebalancer抽象类的实现AutoRebalancer和DelayedAutoRebalancer中，是会用到来计算分区分配的
_rebalanceStrategy =
        getRebalanceStrategy(currentIdealState.getRebalanceStrategy(), partitions, resourceName,
            stateCountMap, maxPartition);
    ZNRecord newMapping = _rebalanceStrategy
        .computePartitionAssignment(allNodes, liveNodes, currentMapping, clusterData);
        


public interface RebalanceStrategy<T extends BaseControllerDataProvider> {
  String DEFAULT_REBALANCE_STRATEGY = "DEFAULT"; //默认为DEFAULT

  /**
   * 为重平衡策略执行必要的初始化
   *
   * @param resourceName
   * @param partitions
   * @param states
   * @param maximumPerNode
   */
  void init(String resourceName, final List<String> partitions,
      final LinkedHashMap<String, Integer> states, int maximumPerNode);

  /**
   * 为给定的resource计算偏好list（preference lists）以及可选的分区状态映射
   *
   * @param liveNodes
   * @param currentMapping
   * @param allNodes
   * @return
   */
  ZNRecord computePartitionAssignment(final List<String> allNodes, final List<String> liveNodes,
      final Map<String, Map<String, String>> currentMapping,
      T clusterData);
}


此接口的类关系：
RebalanceStrategy 
-> AutoRebalanceStrategy 

-> CrushRebalanceStrategy 
基于CRUSH的分区映射策略。
-> MultiRoundCrushRebalanceStrategy 
多轮CRUSH分割映射策略。在分区数较少的情况下，这样可以提供更均匀的分区分布
但在节点中断期间要重新洗牌的分区数可能高于CrushRebalanceStrategy。

=> AbstractEvenDistributionRebalanceStrategy implements RebalanceStrategy
=> ConstraintRebalanceStrategy
基于约束的再平衡策略。根据指定的约束计算赋值。
=> CrushEdRebalanceStrategy 
公平分发的CRUSH，这是一种基于CRUSH算法的自动再平衡策略。
这使得分区分布均匀，但在节点中断期间要重新排列的分区数量可能很高。

```

## AbstractRebalancer抽象类

```
/**
 * 这是一个抽象的rebalancer，为Helix rebalancer定义了许多默认的行为，同时给出了一些公用的工具性方法
 */
public abstract class AbstractRebalancer<T extends BaseControllerDataProvider> implements Rebalancer<T>,
    MappingCalculator<T> {
  // 这些应该是final的，但是在init方法中被初始化，而不是在构造函数
  protected HelixManager _manager;
  protected RebalanceStrategy<T> _rebalanceStrategy;

  private static final Logger LOG = LoggerFactory.getLogger(AbstractRebalancer.class);

  @Override
  public void init(HelixManager manager) {
    this._manager = manager;
    this._rebalanceStrategy = null;
  }

//这里是Rebalancer接口的核心方法，并没有实现
  @Override
  public abstract IdealState computeNewIdealState(
      String resourceName, IdealState currentIdealState, CurrentStateOutput currentStateOutput,
      T clusterData);

  /**
   * 为所有分区计算最佳状态，这里是MappingCalculator接口
   * 这是一个默认实现，如果子类的需求不同，子类应重新实现
   *
   * @param cache
   * @param idealState
   * @param resource
   * @param currentStateOutput 提供每个分区的当前状态以及正在进行中的状态转换
   * @return 返回了ResourceAssignment
   */
  @Override
  public ResourceAssignment computeBestPossiblePartitionState(
      T cache, IdealState idealState, Resource resource,
      CurrentStateOutput currentStateOutput) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Processing resource:" + resource.getResourceName());
    }
    //状态模型名称
    String stateModelDefName = idealState.getStateModelDefRef();
    //从cache中获取状态模型定义
    StateModelDefinition stateModelDef = cache.getStateModelDef(stateModelDefName);
    //新建一个resource的分区分配
    ResourceAssignment partitionMapping = new ResourceAssignment(resource.getResourceName());
    //遍历所有分区
    for (Partition partition : resource.getPartitions()) {
    //获取分区被禁用的节点列表
      Set<String> disabledInstancesForPartition =
          cache.getDisabledInstancesForPartition(resource.getResourceName(), partition.toString());
          //获取偏好的列表，内部调用 1，传入了集群存活的节点
      List<String> preferenceList = getPreferenceList(partition, idealState,
          Collections.unmodifiableSet(cache.getLiveInstances().keySet()));
          //分区最佳状态计算，内部调用 2，
      Map<String, String> bestStateForPartition =
          computeBestPossibleStateForPartition(cache.getLiveInstances().keySet(), stateModelDef,
              preferenceList, currentStateOutput, disabledInstancesForPartition, idealState,
              cache.getClusterConfig(), partition);
      partitionMapping.addReplicaMap(partition, bestStateForPartition);
    }
    return partitionMapping;
  }
  
  //内部调用1，返回的是偏好节点列表，
  public static List<String> getPreferenceList(Partition partition, IdealState idealState,
      Set<String> eligibleInstances) {
      //获取分区的理想状态配置
    List<String> listField = idealState.getPreferenceList(partition.getPartitionName());

//配置不为空，size是1，并且配置是ANY_LIVEINSTANCE的话，对合格的节点排序后返回，否则，返回配置
    if (listField != null && listField.size() == 1
        && IdealState.IdealStateConstants.ANY_LIVEINSTANCE.toString().equals(listField.get(0))) {
      List<String> prefList = new ArrayList<String>(eligibleInstances);
      Collections.sort(prefList);
      return prefList;
    } else {
      return listField;
    }
  }
  
  //内部调用2，为分区计算最佳状态
  //参数：存活节点，状态模型定义，偏好列表，当前状态，分区被禁用的节点，理想状态，集群配置，分区
  protected Map<String, String> computeBestPossibleStateForPartition(Set<String> liveInstances,
      StateModelDefinition stateModelDef, List<String> preferenceList,
      CurrentStateOutput currentStateOutput, Set<String> disabledInstancesForPartition,
      IdealState idealState, ClusterConfig clusterConfig, Partition partition) {

//通过当前的currentStateOutput获取到当前的状态map
    Map<String, String> currentStateMap =
        currentStateOutput.getCurrentStateMap(idealState.getResourceName(), partition);

    if (currentStateMap == null) {
      currentStateMap = Collections.emptyMap();
    }

    // (1) 如果分区从理想状态IS移除或者IS被删除，不管节点是否是禁用的，转移到DROPPED状态
    //内部调用 3
    if (preferenceList == null) {
      return computeBestPossibleMapForDroppedResource(currentStateMap);
    }

    // (2) 如果资源被禁用了，如果它不在ERROR状态，转换为初始状态如OFFLINE
    //内部调用4
    if (!idealState.isEnabled()) {
      return computeBestPossibleMapForDisabledResource(currentStateMap, stateModelDef);
    }

    //否则进行计算，内部调用5
    return computeBestPossibleMap(preferenceList, stateModelDef, currentStateMap, liveInstances,
        disabledInstancesForPartition);
  }
  
  //内部调用3，将当前状态map中设置为DROPPED
  protected Map<String, String> computeBestPossibleMapForDroppedResource(Map<String, String> currentStateMap) {
    Map<String, String> bestPossibleStateMap = new HashMap<String, String>();
    for (String instance : currentStateMap.keySet()) {
      bestPossibleStateMap.put(instance, HelixDefinedState.DROPPED.toString());
    }
    return bestPossibleStateMap;
  }
  
  //内部调用4
  protected Map<String, String> computeBestPossibleMapForDisabledResource(Map<String, String> currentStateMap
      , StateModelDefinition stateModelDef) {
    Map<String, String> bestPossibleStateMap = new HashMap<String, String>();
    for (String instance : currentStateMap.keySet()) {
      if (!HelixDefinedState.ERROR.name().equals(currentStateMap.get(instance))) {
        bestPossibleStateMap.put(instance, stateModelDef.getInitialState());
      }
    }
    return bestPossibleStateMap;
  }
  
  //内部调用 5
  /**
   * 这个方法为分区生成instance->state映射。基于他的偏好preferenceList和状态模型定义
   * preferenceList在不同的rebalancer可能会不同，比如DelayedAutoRebalancer
   * 这个方法也确保一些边界情况，像是disabled的节点或者ERROR的节点能被正确处理
   * currentStateMap必须是非空的
   */
  protected Map<String, String> computeBestPossibleMap(List<String> preferenceList, StateModelDefinition stateModelDef,
      Map<String, String> currentStateMap, Set<String> liveInstances, Set<String> disabledInstancesForPartition) {

    Map<String, String> bestPossibleStateMap = new HashMap<>();

    // (1) 节点有当前状态，但是不在偏好列表中，不管他是否被禁用，都丢弃
    for (String instance : currentStateMap.keySet()) {
      if (!preferenceList.contains(instance)) {
        bestPossibleStateMap.put(instance, HelixDefinedState.DROPPED.name());
      }
    }

    // (2) 如果节点被禁用，并且在偏好列表中，设置为初始状态；当心条件判断
    for (String instance : preferenceList) {
      if (disabledInstancesForPartition.contains(instance)) {
        if (currentStateMap.containsKey(instance)) {
        //偏好节点在当前状态里，并且不是ERROR状态，变为初始状态
          if (!currentStateMap.get(instance).equals(HelixDefinedState.ERROR.name())) {
            bestPossibleStateMap.put(instance, stateModelDef.getInitialState());
          }
        } else {
        //如果偏好中的不在当前状态，也要添加，并设置为初始状态
          if (liveInstances.contains(instance)) {
            bestPossibleStateMap.put(instance, stateModelDef.getInitialState());
          }
        }
      }
    }

    // (3) 为节点分配正常的状态
    // 当选择类似于MASTER的高级状态时，优先从已经在二级状态如SLAVE中选择；而不是更低级的状态
    // 因为二级状态的将使用更少的时间来转换为高级状态，这样可能会对app的可用性造成最小的影响
    // 为了实现，基于CurrentState对preferenceList进行排序；把高级状态和二级状态视为同一优先级；
    // 并且依赖Collections.sort() 排序是稳定的.
    List<String> statesPriorityList = stateModelDef.getStatesPriorityList();
    Set<String> assigned = new HashSet<>();
    Set<String> liveAndEnabled = new HashSet<>(liveInstances);
    //存活的并且可用的节点
    liveAndEnabled.removeAll(disabledInstancesForPartition);

    for (String state : statesPriorityList) {
      // 使用特定的排序的preferenceList 来选择顶级状态的节点
      if (state.equals(statesPriorityList.get(0))) {
        List<String> preferenceListForTopState = new ArrayList<>(preferenceList);
        
        //用的是这个比较器 TopStatePreferenceListComparator
        
        Collections.sort(preferenceListForTopState,
            new TopStatePreferenceListComparator(currentStateMap, stateModelDef));
        preferenceList = preferenceListForTopState;
      }

      //处于某种状态的副本数量，内部调用6
      int stateCount =
          getStateCount(state, stateModelDef, liveAndEnabled.size(), preferenceList.size());
      //遍历偏好列表
      for (String instance : preferenceList) {
        if (stateCount <= 0) {
          break;
        }
        //分配结果里不含该节点，并且节点还存活和可用的话
        if (!assigned.contains(instance) && liveAndEnabled.contains(instance)) {
        //当前是ERROR状态的节点，依然是ERROR
          if (HelixDefinedState.ERROR.toString().equals(currentStateMap.get(instance))) {
            bestPossibleStateMap.put(instance, HelixDefinedState.ERROR.toString());
          } else {
          //否则设置为正确的状态
            bestPossibleStateMap.put(instance, state);
            stateCount--;
          }
          //将节点加入已分配节点，下次循环不再使用
          assigned.add(instance);
        }
      }
    }

    return bestPossibleStateMap;
  }
  
  //内部调用6
  public static int getStateCount(String state, StateModelDefinition stateModelDef, int liveAndEnabledSize,
      int preferenceListSize) {
    String num = stateModelDef.getNumInstancesPerState(state);
    int stateCount = -1;
    if ("N".equals(num)) {
      stateCount = liveAndEnabledSize;
    } else if ("R".equals(num)) {
      stateCount = preferenceListSize;
    } else {
      try {
        stateCount = Integer.parseInt(num);
      } catch (Exception e) {
        LOG.error("Invalid count for state:" + state + " ,count=" + num);
      }
    }

    return stateCount;
  }
  
  //然后其他的方法都是额外的工具类方法了
  /**
   * 查找resource的缓存过的理想mapping，如果存在，不再进行再次计算
   * 缓存清理时机：在ResourceControllerDataProvider中，如果集群状态有任何变化都会导致潜在的理想状态变化
   * 这会避免AutoRebalanceStrategy中的flip-flop问题，同时也能改善性能，因为不需要每次都计算IS
   */
  protected IdealState getCachedIdealState(String resourceName, ResourceControllerDataProvider clusterData) {
    ZNRecord cachedIdealMapping = clusterData.getCachedIdealMapping(resourceName);
    if (cachedIdealMapping != null) {
      return new IdealState(cachedIdealMapping);
    }

    return null;
  }

//当前的mapping
  protected Map<String, Map<String, String>> currentMapping(CurrentStateOutput currentStateOutput,
      String resourceName, List<String> partitions, Map<String, Integer> stateCountMap) {

    Map<String, Map<String, String>> map = new HashMap<>();

    for (String partition : partitions) {
      Map<String, String> curStateMap =
          currentStateOutput.getCurrentStateMap(resourceName, new Partition(partition));
      map.put(partition, new HashMap<String, String>());
      for (String node : curStateMap.keySet()) {
        String state = curStateMap.get(node);
        map.get(partition).put(node, state);
      }

      Map<String, String> pendingStateMap =
          currentStateOutput.getPendingStateMap(resourceName, new Partition(partition));
      for (String node : pendingStateMap.keySet()) {
        String state = pendingStateMap.get(node);
        map.get(partition).put(node, state);
      }
    }
    return map;
  }

//获取RB策略
  protected RebalanceStrategy<T> getRebalanceStrategy(
      String rebalanceStrategyName, List<String> partitions, String resourceName,
      LinkedHashMap<String, Integer> stateCountMap, int maxPartition) {
    RebalanceStrategy rebalanceStrategy;
    if (rebalanceStrategyName == null || rebalanceStrategyName
        .equalsIgnoreCase(RebalanceStrategy.DEFAULT_REBALANCE_STRATEGY)) {
      rebalanceStrategy =
          new AutoRebalanceStrategy(resourceName, partitions, stateCountMap, maxPartition);
    } else {
      try {
        rebalanceStrategy = RebalanceStrategy.class
            .cast(HelixUtil.loadClass(getClass(), rebalanceStrategyName).newInstance());
        rebalanceStrategy.init(resourceName, partitions, stateCountMap, maxPartition);
      } catch (ClassNotFoundException ex) {
        throw new HelixException(
            "Exception while invoking custom rebalance strategy class: " + rebalanceStrategyName,
            ex);
      } catch (InstantiationException ex) {
        throw new HelixException(
            "Exception while invoking custom rebalance strategy class: " + rebalanceStrategyName,
            ex);
      } catch (IllegalAccessException ex) {
        throw new HelixException(
            "Exception while invoking custom rebalance strategy class: " + rebalanceStrategyName,
            ex);
      }
    }

    return rebalanceStrategy;
  }

 
}
```

#### PreferenceListNodeComparator

```
/**
 * Sorter for nodes that sorts according to the CurrentState of the partition, based on the state priority defined
 * in the state model definition.
 * If the CurrentState doesn't exist, treat it as having lowest priority(Integer.MAX_VALUE).
 */
protected static class PreferenceListNodeComparator implements Comparator<String> {
  protected final Map<String, String> _currentStateMap;
  protected final StateModelDefinition _stateModelDef;
  protected final List<String> _preferenceList;

  public PreferenceListNodeComparator(Map<String, String> currentStateMap,
      StateModelDefinition stateModelDef, List<String> preferenceList) {
    _currentStateMap = currentStateMap;
    _stateModelDef = stateModelDef;
    _preferenceList = preferenceList;
  }

  @Override
  public int compare(String ins1, String ins2) {
    // condition :
    // 1. both in preference list, keep the order in preference list
    // 2. one them in preference list, the one in preference list has higher priority
    // 3. none of them in preference list, sort by state.
    if (_preferenceList.contains(ins1) && _preferenceList.contains(ins2)) {
      return _preferenceList.indexOf(ins1) - _preferenceList.indexOf(ins2);
    } else if (_preferenceList.contains(ins1)) {
      return -1;
    } else if (_preferenceList.contains(ins2)) {
      return 1;
    }
    Integer p1 = Integer.MAX_VALUE;
    Integer p2 = Integer.MAX_VALUE;

    Map<String, Integer> statesPriorityMap = _stateModelDef.getStatePriorityMap();
    String state1 = _currentStateMap.get(ins1);
    String state2 = _currentStateMap.get(ins2);
    if (state1 != null && statesPriorityMap.containsKey(state1)) {
      p1 = statesPriorityMap.get(state1);
    }
    if (state2 != null && statesPriorityMap.containsKey(state2)) {
      p2 = statesPriorityMap.get(state2);
    }

    return p1.compareTo(p2);
  }
}
```

## FULL_AUTO - AutoRebalancer

```
/**
 * 这是full automatic对应的Rebalancer。他会计算resource的理想状态，自动调整集群节点的增加和删除；
 * 这包括计算一个新的偏好列表preference list，以及基于这个列表决定分区到节点和状态的mapping
 * 输入是当前的节点上的分配，以及现存的实例偏好，如果有的话
 * 输出是preference list和mapping，基于preference list
 * 例如分区p有一个副本replica在节点k上，状态是s
 */
public class AutoRebalancer extends AbstractRebalancer<ResourceControllerDataProvider> {
  private static final Logger LOG = LoggerFactory.getLogger(AutoRebalancer.class);

  @Override
  //AbstractRebalancer抽象类中没有实现的Rebalancer的接口，在这里实现了
  public IdealState computeNewIdealState(String resourceName,
      IdealState currentIdealState, CurrentStateOutput currentStateOutput,
      ResourceControllerDataProvider clusterData) {

//首先是检测了是否有cache，上面有提到cache的由来
    IdealState cachedIdealState = getCachedIdealState(resourceName, clusterData);
    if (cachedIdealState != null) {
      LOG.debug("Use cached IdealState for " + resourceName);
      return cachedIdealState;
    }

    LOG.info("Computing IdealState for " + resourceName);
    //分区列表
    List<String> partitions = new ArrayList<>(currentIdealState.getPartitionSet());
    //状态机名称
    String stateModelName = currentIdealState.getStateModelDefRef();
    //状态模型定义 ResourceControllerDataProvider上的
    StateModelDefinition stateModelDef = clusterData.getStateModelDef(stateModelName);
    if (stateModelDef == null) {
      LOG.error("State Model Definition null for resource: " + resourceName);
      throw new HelixException("State Model Definition null for resource: " + resourceName);
    }
    //当前集群的存活节点
    Map<String, LiveInstance> liveInstance = clusterData.getLiveInstances();
    //为resource确定副本数
    //首先会从IS的getReplicas方法，获取resource下的每个分区的副本数
    //SEMI_AUTO下，如果没有配置list，返回0；否则获取的是配置的list中第一个分区设置的副本数
    //CUSTOMIZED下，如果没有配置list，返回0；否则获取的是配置的map中第一个分区设置的副本数
    //其他情况IS的getReplicas返回0
    //如果返回不是整数，而是ANY_LIVEINSTANCE，那么使用存活的节点数
    //否则返回0
    int replicas = currentIdealState.getReplicaCount(liveInstance.size());
    
    //这个按照state的优先级返回一个有顺序的state->count的map
    //检查state的配置，N=存活的节点数；R=根据存活的节点动态变化；用户的设置，否则-1
    LinkedHashMap<String, Integer> stateCountMap = stateModelDef
        .getStateCountMap(liveInstance.size(), replicas);
    //存活节点名称
    List<String> liveNodes = new ArrayList<>(liveInstance.keySet());
    //所有节点名称
    List<String> allNodes = new ArrayList<>(clusterData.getAllInstances());
    // 所有节点。去除禁用的节点，包括存活+DEAD
    allNodes.removeAll(clusterData.getDisabledInstances());
    // 存活节点。去除存活节点中的禁用的节点
    liveNodes.retainAll(allNodes);

    //当前的mapping
    Map<String, Map<String, String>> currentMapping =
        currentMapping(currentStateOutput, resourceName, partitions, stateCountMap);

    // 如果节点上打了resource的tag，那么仅使用这些打了tag的节点
    Set<String> taggedNodes = new HashSet<String>();
    Set<String> taggedLiveNodes = new HashSet<String>();
    //从IS上获取INSTANCE_GROUP_TAG配置，如果设置了这个
    if (currentIdealState.getInstanceGroupTag() != null) {
    //遍历所有节点，找出包含这个tag的节点，把它添加到打tag的节点列表，并且进行存活检查
      for (String instanceName : allNodes) {
        if (clusterData.getInstanceConfigMap().get(instanceName)
            .containsTag(currentIdealState.getInstanceGroupTag())) {
          taggedNodes.add(instanceName);
          if (liveInstance.containsKey(instanceName)) {
            taggedLiveNodes.add(instanceName);
          }
        }
      }
      //如果可以按照tag的逻辑匹配到节点
      if (!taggedLiveNodes.isEmpty()) {
        // live nodes exist that have this tag
        if (LOG.isInfoEnabled()) {
          LOG.info("found the following participants with tag "
              + currentIdealState.getInstanceGroupTag() + " for " + resourceName + ": "
              + taggedLiveNodes);
        }
      } else if (taggedNodes.isEmpty()) {
        //如果不能按照tag找到任何节点，但资源配置了tag，记录日志
        //换句话说，没有节点打了这个tag，可能是忘记打了
        // no live nodes and no configured nodes have this tag
        LOG.warn("Resource " + resourceName + " has tag " + currentIdealState.getInstanceGroupTag()
            + " but no configured participants have this tag");
      } else {
        //否则就是节点上打tag这个做了，没有遗忘，但是没有存活的节点可以使用
        // configured nodes have this tag, but no live nodes have this tag
        LOG.warn("Resource " + resourceName + " has tag " + currentIdealState.getInstanceGroupTag()
            + " but no live participants have this tag");
      }
      allNodes = new ArrayList<>(taggedNodes);
      liveNodes = new ArrayList<>(taggedLiveNodes);
    }

    //排序以应对一致性偏好的分配
    Collections.sort(allNodes);
    Collections.sort(liveNodes);

    //获取节点上可以运行的最大分区数
    int maxPartition = currentIdealState.getMaxPartitionsPerInstance();
    //获取重平衡策略
    _rebalanceStrategy =
        getRebalanceStrategy(currentIdealState.getRebalanceStrategy(), partitions, resourceName, stateCountMap, maxPartition);
    //使用重平衡策略来计算分区分配，也就是mapping，所以这里肯定设计重平衡接口的实现类了，后面继再看
    ZNRecord newMapping = _rebalanceStrategy
        .computePartitionAssignment(allNodes, liveNodes, currentMapping, clusterData);

    if (LOG.isDebugEnabled()) {
      LOG.debug("currentMapping: " + currentMapping);
      LOG.debug("stateCountMap: " + stateCountMap);
      LOG.debug("liveNodes: " + liveNodes);
      LOG.debug("allNodes: " + allNodes);
      LOG.debug("maxPartition: " + maxPartition);
      LOG.debug("newMapping: " + newMapping);
    }
    //新的理想状态
    IdealState newIdealState = new IdealState(resourceName);
    //复制以前的配置    newIdealState.getRecord().setSimpleFields(
    currentIdealState.getRecord().getSimpleFields());
    //设置重平衡模式为FULL_AUTO
    newIdealState.setRebalanceMode(RebalanceMode.FULL_AUTO);
    //设置list字段原来的值，把新的mapping弄进去
    newIdealState.getRecord().setListFields(newMapping.getListFields());

    return newIdealState;
  }
}

//看起来AutoRebalancer就是自动确定了分区分配，failover之类的跟抽象类一样
```

## SEMI_AUTO - SemiAutoRebalancer

```
/**
 * 这是semi-automatic模式的rebalancer. 它的职责是根据预先定义的preference list来给出理想状态map
 * 输入是optional的当前的分配方案，以及必要的已经存在的节点的配置
 * 输出是基于preference list的mapping，比如分区p在节点k上有一个副本replica，状态是s
 * 
 * 注意：因为SemiAutoRebalancer被Resource controller和Workflow controller用到了，
 * 所以我们需要使用模板template作为data provider 类型
 */
public class SemiAutoRebalancer<T extends BaseControllerDataProvider>
    extends AbstractRebalancer<T> {

  @Override
  public IdealState computeNewIdealState(String resourceName, IdealState currentIdealState,
      CurrentStateOutput currentStateOutput, T clusterData) {
      //这里就是返回了currentIdealState
    return currentIdealState;
  }
}
```

## CUSTOMIZED - CustomRebalancer

```
/**
 * 这是custom 模式下的Rebalancer. 它的职责是检查现有的mapping与当前存活的实例，然后根据需要把分区的状态标记为dropped或者erroneous
 * 输入是当前的分配方案以及一些必要的节点配置
 * 输出是一个基于preference list的验证过的mapping
 * 例如分区p在节点k上有一个副本，状态为s, s可能是dropped 或者 error
 */
public class CustomRebalancer extends AbstractRebalancer<ResourceControllerDataProvider> {
  private static final Logger LOG = LoggerFactory.getLogger(CustomRebalancer.class);

  //这里跟SEMI_AUTO一样，都是返回配置
  @Override
  public IdealState computeNewIdealState(String resourceName, IdealState currentIdealState,
      CurrentStateOutput currentStateOutput, ResourceControllerDataProvider clusterData) {
    return currentIdealState;
  }

  @Override
  //这里重写了AbstractRebalancer为分区确定state的方法
  //说明这种模式下跟AbstractRebalancer的默认行为不一样
  public ResourceAssignment computeBestPossiblePartitionState(ResourceControllerDataProvider cache,
      IdealState idealState, Resource resource, CurrentStateOutput currentStateOutput) {
    // 首先还是看cache是否存在，如果存在就不用重复计算了
    // cache会被清理，ResourceControllerDataProvider会在集群状态有任何变化的时候去过期cache，因为任何集群方面的变化都可能会影响到BestPossible state.
    ResourceAssignment partitionMapping =
        cache.getCachedResourceAssignment(resource.getResourceName());
    if (partitionMapping != null) {
      return partitionMapping;
    }

    LOG.info("Computing BestPossibleMapping for " + resource.getResourceName());

    String stateModelDefName = idealState.getStateModelDefRef();
    //同样还是拿到resource的状态模型定义
    StateModelDefinition stateModelDef = cache.getStateModelDef(stateModelDefName);
    // 新的ResourceAssignment，处理后会返回它
    partitionMapping = new ResourceAssignment(resource.getResourceName());
    //遍历resource的每个分区
    for (Partition partition : resource.getPartitions()) {
    
      //当前分区的状态map，given (resource, partition), returns (instance->currentState) map
      //CurrentStateOutput存了当前的状态以及正在处理的消息，可以理解为toState and fromState正在转化中的那些
      Map<String, String> currentStateMap =
          currentStateOutput.getCurrentStateMap(resource.getResourceName(), partition);
      
      //被禁用的节点，是通过ResourceControllerDataProvider取的
      Set<String> disabledInstancesForPartition =
          cache.getDisabledInstancesForPartition(resource.getResourceName(), partition.toString());
      
      //获取当前分区的当前mapping
      //IS里仅仅是当前的分区mapping，是副本所在的节点->state的映射
      Map<String, String> idealStateMap =
          idealState.getInstanceStateMap(partition.getPartitionName());
      
      //使用computeCustomizedBestStateForPartition来获得最佳状态
      //默认行为是按照节点自动计算，所以这里是关键
      
      Map<String, String> bestStateForPartition =
          computeCustomizedBestStateForPartition(cache, stateModelDef, idealStateMap,
              currentStateMap, disabledInstancesForPartition, idealState.isEnabled());
      partitionMapping.addReplicaMap(partition, bestStateForPartition);
    }
    
    //设置缓存
    cache.setCachedResourceAssignment(resource.getResourceName(), partitionMapping);
    if (LOG.isDebugEnabled()) {
      LOG.debug(String.format("Processing resource: %s", resource.getResourceName()));
      LOG.debug(String.format("Final Mapping of resource : %s", partitionMapping.toString()));
    }
    return partitionMapping;
  }

  /**
   * compute best state for resource in CUSTOMIZED ideal state mode
   * CUSTOMIZED模式下为resource计算最佳state
   * @param cache ResourceControllerDataProvider
   * @param stateModelDef StateModelDefinition
   * @param idealStateMap IS的当前mapping
   * @param currentStateMap 当前状态mapping
   * @param disabledInstancesForPartition 被禁用的节点
   * @param isResourceEnabled resource是否被启用
   * @return
   */
  private Map<String, String> computeCustomizedBestStateForPartition(
      ResourceControllerDataProvider cache, StateModelDefinition stateModelDef,
      Map<String, String> idealStateMap, Map<String, String> currentStateMap,
      Set<String> disabledInstancesForPartition, boolean isResourceEnabled) {
     
    //这是要返回的结果
    Map<String, String> instanceStateMap = new HashMap<>();

    //如果理想状态被删除，idealStateMap 会是 null/empty，丢弃所有资源
    if (currentStateMap != null) {
      //当前状态对应的节点，遍历
      for (String instance : currentStateMap.keySet()) {
        //如果理想状态是空或者理想状态里不包含此节点，并且此节点对此分区没有被禁用，切换为DROPPED
        if ((idealStateMap == null || !idealStateMap.containsKey(instance))
            && !disabledInstancesForPartition.contains(instance)) {
          // 如果是丢弃状态，不管是不是被禁用的，都丢弃DROPPED
          instanceStateMap.put(instance, HelixDefinedState.DROPPED.toString());
        } else if ((currentStateMap.get(instance) == null || !currentStateMap.get(instance).equals(HelixDefinedState.ERROR.name()))
            && (!isResourceEnabled || disabledInstancesForPartition.contains(instance))) {
          //否则，如果节点的当前状态为空
          //或者节点上副本的状态为error
          //并且资源是禁用的，或者分区这个节点没有被禁用
          //即如果禁用了，并且不处于ERROR状态，转换到初始状态，如OFFLINE
          instanceStateMap.put(instance, stateModelDef.getInitialState());
        }
      }
    }

    //如果理想状态被删除了，直接返回上面的结果了
    if (idealStateMap == null) {
      return instanceStateMap;
    }

    //获取到存活的节点
    Map<String, LiveInstance> liveInstancesMap = cache.getLiveInstances();
    //遍历理想状态中的节点
    for (String instance : idealStateMap.keySet()) {
      // 有当前mapping，并且当前状态不是ERROR
      boolean notInErrorState = currentStateMap != null
          && !HelixDefinedState.ERROR.toString().equals(currentStateMap.get(instance));
      // 节点是否被禁用，或者资源是否被禁用
      boolean enabled = !disabledInstancesForPartition.contains(instance) && isResourceEnabled;

      //如果节点不存活，实例的mapping将不会展示在BestPossibleMapping和ExternalView中
      if (liveInstancesMap.containsKey(instance) && notInErrorState) {
        if (enabled) {
          instanceStateMap.put(instance, idealStateMap.get(instance));
        } else {
          // if disabled, put it in initial state
          instanceStateMap.put(instance, stateModelDef.getInitialState());
        }
      }
    }

    return instanceStateMap;
  }
}

//与AbstractRebalancer的不同是，AbstractRebalancer会有helix自动计算出mapping
//而CUSTOMIZED模式下，这个mapping是由APP来决定的
//computeBestPossiblePartitionState是MappingCalculator的方法，所以要看一下它的实现类以及他是在哪里被调用的
//它的实现类有AbstractRebalancer，CustomRebalancer，DelayedAutoRebalancer，DeprecatedTaskRebalancer（废弃），JobRebalancer，TaskRebalancer，WorkflowRebalancer
//这些Rebalancer将会在BestPossibleStateCalcStage被强制转换为MappingCalculator接口的实例
//task框架中的暂时不看，然后定位到BestPossibleStateCalcStage这个类

```

## BestPossibleStateCalcStage流程分析

```
ZKHelixManager中会使用GenericHelixController，
  public void connect() throws Exception {
    switch (_instanceType) {
    case CONTROLLER:
    case CONTROLLER_PARTICIPANT:
      if (_controller == null) {
        _controller = new GenericHelixController(_clusterName, _enabledPipelineTypes);
```

```
/**
 * 控制器的主要目标是保持集群状态尽可能地与理想状态一致
 * 他是通过监听集群状态的变化和调度新的任务来实现集群状态尽可能与理想状态一致来实现的
 * 这个类的每个实例只能控制一个集群
 * 获取所有分区的IdealState, CurrentState ， Messages 
 * 每个分区
 * 1. 从IdealState, CurrentState ， PendingMessages 获取(instance,state) 
 * 2. 计算最佳可能状态的 (instance,state) 对. 这需要前置步骤的数据和状态模型约束
 * 3. 计算 messages/tasks 需要从1到2
 * 4. 选择可以发送的消息，需要消息和状态模型约束
 * 5. 发送消息
 */
public class GenericHelixController implements IdealStateChangeListener,
    LiveInstanceChangeListener, MessageListener, CurrentStateChangeListener,
    ControllerChangeListener, InstanceConfigChangeListener, ResourceConfigChangeListener,
    ClusterConfigChangeListener {
    
1. GenericHelixController() -> createDefaultRegistry() -> rebalancePipeline.addStage(new BestPossibleStateCalcStage());
2. registry.register(ClusterEventType.LiveInstanceChange, dataRefresh, autoExitMaintenancePipeline, liveInstancePipeline, dataPreprocess, externalViewPipeline, rebalancePipeline);
3. handleEvent()
if (dataProvider instanceof ResourceControllerDataProvider) {
      pipelines = _registry
          .getPipelinesForEvent(event.getEventType());
for (Pipeline pipeline : pipelines) {
      event.addAttribute(AttributeName.PipelineType.name(), pipeline.getPipelineType());
      try {
        pipeline.handle(event);
        pipeline.finish();
4.for (Stage stage : _stages) {
      long startTime = System.currentTimeMillis();
      stage.preProcess();
      stage.process(event);
      stage.postProcess();
```



```
BestPossibleStateCalcStage extends AbstractBaseStage
process() -> compute -> validateOfflineInstancesLimit 
                     -> computeResourceBestPossibleState -> 
                     -> updateRebalanceStatus 
                     
             
computeResourceBestPossibleState 
-> getRebalancer
-> getMappingCalculator
-> checkBestPossibleStateCalculation


// ---------以下是代码阅读过程，可以忽略------------
先看看BestPossibleStateCalcStage是在哪用的

1. GenericHelixController，rebalancePipeline.addStage(new BestPossibleStateCalcStage());
2. ClusterExternalViewVerifier，deprecated, please use BestPossibleExternalViewVerifier
3. ClusterStateVerifier，deprecated, please use dedicated verifier classes, such as BestPossibleExternalViewVerifier, etc, in tools.ClusterVerifiers.
4. BestPossibleExternalViewVerifier 这个看起来是在工具包里面命令行手动调用的逻辑
/* verifier that the ExternalViews of given resources (or all resources in the cluster) match its best possible mapping states. */
public class BestPossibleExternalViewVerifier extends ZkHelixClusterVerifier {

重点可能在控制器的逻辑里
```

#### 用户自定义的时机？

helix文档中说到：Helix提供了第三种模式，称为CUSTOMIZED，其中应用程序控制每个副本的位置*和*状态。应用程序需要实现一个回调接口，当集群状态改变时，Helix会调用该接口。在此回调中，应用程序可以重新计算理想状态。然后，Helix将发出适当的transitions，以使*Idealstate*和*Currentstate*收敛。

但并没有说是实现哪个接口，这相当费解

理论上讲，应该不是让用户直接修改GenericHelixController的pipeline

所以推测是使用HelixAdmin上添加监听器的方式来探测集群变化，然后重新设置mapping，这块留给后面探索。

## BestPossibleStateCalcStage源码分析

```
/**
 * Logically independent unit in processing callbacks for cluster changes
 * 逻辑独立单元，在集群改变的时候，处理回调
 */
public interface Stage {
  void init(StageContext context);
  void release();
  void preProcess();
  void postProcess();
  String getStageName();

  /**
   * Actual callback processing logic
   * 实际callback逻辑
   * @param event
   * @throws Exception
   */
  public void process(ClusterEvent event) throws Exception;
}
```

```
// AbstractBaseStage 实现了 Stage
// 但仅仅实现了getStageName，以及增加了两个方法，其他方法的实现是空方法
  public static <T> Future asyncExecute(ExecutorService service, Callable<T> task) {
    if (service != null) {
      return service.submit(task);
    }
    return null;
  }

  protected DedupEventProcessor<String, Runnable> getAsyncWorkerFromClusterEvent(ClusterEvent event,
      AsyncWorkerType workerType) {
    Map<AsyncWorkerType, DedupEventProcessor<String, Runnable>> workerPool =
        event.getAttribute(AttributeName.AsyncFIFOWorkerPool.name());
    if (workerPool != null) {
      if (workerPool.containsKey(workerType)) {
        return workerPool.get(workerType);
      }
    }
    return null;
  }
```

```
BestPossibleStateCalcStage是一个比较完整的实现类
/**
 * 为分区计算最佳可能的 (instance,state) 对
 * 计算是基于IdealState,StateModel,LiveInstance
 */
public class BestPossibleStateCalcStage extends AbstractBaseStage {
//--------------------------------------------------------------------------
// 内部方法调用拓扑
// BestPossibleStateCalcStage extends AbstractBaseStage
// process() 
//   -> compute 计算最佳可能状态
//      -> validateOfflineInstancesLimit 检查离线节点是否超过限制，如果超过，则暂停重平衡
//      -> computeResourceBestPossibleState 计算resource的最佳可能状态 -> 未完
//      -> updateRebalanceStatus 
//                     
//            
//   ->computeResourceBestPossibleState  计算resource的最佳可能状态
//     -> getRebalancer 获取重平衡器
//     -> getMappingCalculator 获取mapping计算器
//       -> rebalancer.init
//       -> rebalancer.computeNewIdealState
//       -> mappingCalculator.computeBestPossiblePartitionState
//     -> checkBestPossibleStateCalculation 检查计算是否成功完成
//     
//---------------------------------------------------------------------------
  private static final Logger logger = LoggerFactory.getLogger(BestPossibleStateCalcStage.class.getName());

  @Override
  public void process(ClusterEvent event) throws Exception {
    _eventId = event.getEventId();
    CurrentStateOutput currentStateOutput =
        event.getAttribute(AttributeName.CURRENT_STATE.name());
    final Map<String, Resource> resourceMap =
        event.getAttribute(AttributeName.RESOURCES_TO_REBALANCE.name());
    final ClusterStatusMonitor clusterStatusMonitor =
        event.getAttribute(AttributeName.clusterStatusMonitor.name());
    ResourceControllerDataProvider cache = event.getAttribute(AttributeName.ControllerDataProvider.name());

    if (currentStateOutput == null || resourceMap == null || cache == null) {
      throw new StageException(
          "Missing attributes in event:" + event + ". Requires CURRENT_STATE|RESOURCES|DataCache");
    }

    //计算最佳可能状态
    final BestPossibleStateOutput bestPossibleStateOutput =
        compute(event, resourceMap, currentStateOutput);
    event.addAttribute(AttributeName.BEST_POSSIBLE_STATE.name(), bestPossibleStateOutput);

    final Map<String, InstanceConfig> instanceConfigMap = cache.getInstanceConfigMap();
    final Map<String, StateModelDefinition> stateModelDefMap = cache.getStateModelDefMap();
    
    //异步执行了监控数据相关的逻辑
    asyncExecute(cache.getAsyncTasksThreadPool(), new Callable<Object>() {
      @Override
      public Object call() {
        try {
          if (clusterStatusMonitor != null) {
            clusterStatusMonitor
                .setPerInstanceResourceStatus(bestPossibleStateOutput, instanceConfigMap,
                    resourceMap, stateModelDefMap);
          }
        } catch (Exception e) {
          LogUtil
              .logError(logger, _eventId, "Could not update cluster status metrics!", e);
        }
        return null;
      }
    });
  }

  private BestPossibleStateOutput compute(ClusterEvent event, Map<String, Resource> resourceMap,
      CurrentStateOutput currentStateOutput) {
    ResourceControllerDataProvider cache = event.getAttribute(AttributeName.ControllerDataProvider.name());
    BestPossibleStateOutput output = new BestPossibleStateOutput();

    HelixManager helixManager = event.getAttribute(AttributeName.helixmanager.name());
    ClusterStatusMonitor clusterStatusMonitor =
        event.getAttribute(AttributeName.clusterStatusMonitor.name());

    // 检查是否离线/禁用的节点数量达到了设定的阈值，如果是暂停重平衡
    boolean isValid = validateOfflineInstancesLimit(cache,
        (HelixManager) event.getAttribute(AttributeName.helixmanager.name()));

    final List<String> failureResources = new ArrayList<>();
    Iterator<Resource> itr = resourceMap.values().iterator();
    while (itr.hasNext()) {
      //循环每一个resource
      Resource resource = itr.next();
      boolean result = false;
      try {
        //计算resource的最佳可能状态
        result =
            computeResourceBestPossibleState(event, cache, currentStateOutput, resource, output);
      } catch (HelixException ex) {
        LogUtil.logError(logger, _eventId,
            "Exception when calculating best possible states for " + resource.getResourceName(),
            ex);

      }
      if (!result) {
        //如果发生错误，记录
        failureResources.add(resource.getResourceName());
        LogUtil.logWarn(logger, _eventId,
            "Failed to calculate best possible states for " + resource.getResourceName());
      }
    }

    // 检查和报告resource是否rebalance失败了
    updateRebalanceStatus(!isValid || !failureResources.isEmpty(), failureResources, helixManager,
        cache, clusterStatusMonitor,
        "Failed to calculate best possible states for " + failureResources.size() + " resources.");

    return output;
  }

  private void updateRebalanceStatus(final boolean hasFailure, final List<String> failedResources,
      final HelixManager helixManager, final ResourceControllerDataProvider cache,
      final ClusterStatusMonitor clusterStatusMonitor, final String errorMessage) {
    
    //异步执行监控等
    asyncExecute(cache.getAsyncTasksThreadPool(), new Callable<Object>() {
      @Override
      public Object call() {
        try {
          if (hasFailure) {
            /* TODO Enable this update when we resolve ZK server load issue. This will cause extra write to ZK.
            if (_statusUpdateUtil != null) {
              _statusUpdateUtil
                  .logError(StatusUpdateUtil.ErrorType.RebalanceResourceFailure, this.getClass(),
                      errorMessage, helixManager);
            }
            */
            LogUtil.logWarn(logger, _eventId, errorMessage);
          }
          if (clusterStatusMonitor != null) {
            clusterStatusMonitor.setRebalanceFailureGauge(hasFailure);
            clusterStatusMonitor.setResourceRebalanceStates(failedResources,
                ResourceMonitor.RebalanceStatus.BEST_POSSIBLE_STATE_CAL_FAILED);
          }
        } catch (Exception e) {
          LogUtil.logError(logger, _eventId, "Could not update cluster status!", e);
        }
        return null;
      }
    });
  }

  //检查离线或者禁用的节点数是否达到了配置的limit，如果超过了，暂停rebalancer，并且抛出异常来终止重平衡环节
  private boolean validateOfflineInstancesLimit(final ResourceControllerDataProvider cache,
      final HelixManager manager) {
      //集群上设置的属性
    int maxOfflineInstancesAllowed = cache.getClusterConfig().getMaxOfflineInstancesAllowed();
    if (maxOfflineInstancesAllowed >= 0) {
      int offlineCount = cache.getAllInstances().size() - cache.getEnabledLiveInstances().size();
      //超出限制
      if (offlineCount > maxOfflineInstancesAllowed) {
        String errMsg = String.format(
            "Offline Instances count %d greater than allowed count %d. Stop rebalance and put the cluster %s into maintenance mode.",
            offlineCount, maxOfflineInstancesAllowed, cache.getClusterName());
        if (manager != null) {
          //获取了data访问器
          if (manager.getHelixDataAccessor()
              .getProperty(manager.getHelixDataAccessor().keyBuilder().maintenance()) == null) {
            //如果维护属性没有设置，自动开启维护模式，并附加原因
            manager.getClusterManagmentTool().autoEnableMaintenanceMode(manager.getClusterName(),
                true, errMsg, MaintenanceSignal.AutoTriggerReason.MAX_OFFLINE_INSTANCES_EXCEEDED);
            LogUtil.logWarn(logger, _eventId, errMsg);
          }
        } else {
          LogUtil.logError(logger, _eventId, "Failed to put cluster " + cache.getClusterName()
              + " into maintenance mode, HelixManager is not set!");
        }
        return false;
      }
    }
    return true;
  }
  
  //为resource计算最佳可能状态
  private boolean computeResourceBestPossibleState(ClusterEvent event, ResourceControllerDataProvider cache,
      CurrentStateOutput currentStateOutput, Resource resource, BestPossibleStateOutput output) {
    // 遍历每个理想状态
    // 读取状态模型定义
    // 遍历每个resource
    // 获取属性列表
    // 遍历每个实例名字，检查他是否是存活的，然后分配一个状态
    
    String resourceName = resource.getResourceName();
    LogUtil.logDebug(logger, _eventId, "Processing resource:" + resourceName);
    
    // 理想状态可能会不存在。所以需要从当前状态上获取状态模型名称
    IdealState idealState = cache.getIdealState(resourceName);
    if (idealState == null) {
      // 如果理想状态是空，使用一个空的
      LogUtil.logInfo(logger, _eventId, "resource:" + resourceName + " does not exist anymore");
      idealState = new IdealState(resourceName);
      idealState.setStateModelDefRef(resource.getStateModelDefRef());
    }

    // 跳过resources，那些常规pipeline的任务
    if (idealState.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME)) {
      LogUtil.logWarn(logger, _eventId, String
          .format("Resource %s should not be processed by %s pipeline", resourceName,
              cache.getPipelineName()));
      return false;
    }

    //获取重平衡器
    Rebalancer<ResourceControllerDataProvider> rebalancer =
        getRebalancer(idealState, resourceName, cache.isMaintenanceModeEnabled());
    //获取mapping计算器
    MappingCalculator<ResourceControllerDataProvider> mappingCalculator = getMappingCalculator(rebalancer, resourceName);

    if (rebalancer == null || mappingCalculator == null) {
      LogUtil.logError(logger, _eventId,
          "Error computing assignment for resource " + resourceName + ". no rebalancer found. rebalancer: " + rebalancer
              + " mappingCalculator: " + mappingCalculator);
    }

    if (rebalancer != null && mappingCalculator != null) {
      //如果都不是空，则开始计算
      ResourceAssignment partitionStateAssignment = null;
      try {
        HelixManager manager = event.getAttribute(AttributeName.helixmanager.name());
        //调用rebalancer的初始化方法
        rebalancer.init(manager);
        //调用rebalancer.computeNewIdealState计算理想状态
        
        //到这里，难道Custom模式下是要继承CustomRebalancer，然后重写computeNewIdealState方法？
        idealState =
            rebalancer.computeNewIdealState(resourceName, idealState, currentStateOutput, cache);

        //设置到结果上偏好list
        output.setPreferenceLists(resourceName, idealState.getPreferenceLists());

        // 使用内部MappingCalculator接口来计算最终状态
        // 下一个版本将支持rebalancers计算从start到finish的mapping
        // 计算分区状态分配结果
        partitionStateAssignment = mappingCalculator
            .computeBestPossiblePartitionState(cache, idealState, resource, currentStateOutput);

        if (partitionStateAssignment == null) {
          LogUtil.logWarn(logger, _eventId,
              "PartitionStateAssignment is null, resource: " + resourceName);
          return false;
        }

        //遍历分区状态结果，找到每个分区的副本map，复制到最终结果上
        for (Partition partition : resource.getPartitions()) {
          Map<String, String> newStateMap = partitionStateAssignment.getReplicaMap(partition);
          output.setState(resourceName, partition, newStateMap);
        }

        // 检查计算是否成功完成
        return checkBestPossibleStateCalculation(idealState);
      } catch (HelixException e) {
        // No eligible instance is found.
        LogUtil.logError(logger, _eventId, e.getMessage());
      } catch (Exception e) {
        LogUtil.logError(logger, _eventId,
            "Error computing assignment for resource " + resourceName + ". Skipping." , e);
      }
    }
    // Exception or rebalancer is not found
    return false;
  }

  private boolean checkBestPossibleStateCalculation(IdealState idealState) {
    // 如果replicas 是 0, 表示resource没有完全完成初始化，或者没有准备好去做重平衡
    // 如果是FULL_AUTO模式，并且整个副本equals 0
    if (idealState.getRebalanceMode() == IdealState.RebalanceMode.FULL_AUTO && !idealState
        .getReplicas().equals("0")) {
      
      //理想状态上获取偏好list
      Map<String, List<String>> preferenceLists = idealState.getPreferenceLists();
      if (preferenceLists == null || preferenceLists.isEmpty()) {
        return false;
      }
      int emptyListCount = 0;
      for (List<String> preferenceList : preferenceLists.values()) {
        if (preferenceList.isEmpty()) {
          emptyListCount++;
        }
      }
      // If all lists are empty, rebalance fails completely
      return emptyListCount != preferenceLists.values().size();
    } else {
      //如果不是FULL_AUTO的模式，重平衡不是Helix控制的？（SEMI_AUTO不也是helix控制的吗）
      return true;
    }
  }


  //获取重平衡器
  private Rebalancer<ResourceControllerDataProvider> getRebalancer(IdealState idealState, String resourceName,
      boolean isMaintenanceModeEnabled) {
    Rebalancer<ResourceControllerDataProvider> customizedRebalancer = null;
    //获取理想状态上的重平衡器类名
    String rebalancerClassName = idealState.getRebalancerClassName();
    if (rebalancerClassName != null) {
      if (logger.isDebugEnabled()) {
        LogUtil.logDebug(logger, _eventId,
            "resource " + resourceName + " use idealStateRebalancer " + rebalancerClassName);
      }
      try {
        //通过反射获取重平衡器的实例
        customizedRebalancer = Rebalancer.class
            .cast(HelixUtil.loadClass(getClass(), rebalancerClassName).newInstance());
      } catch (Exception e) {
        LogUtil.logError(logger, _eventId,
            "Exception while invoking custom rebalancer class:" + rebalancerClassName, e);
      }
    }

    Rebalancer<ResourceControllerDataProvider> rebalancer = null;
    //查看理想状态上的重平衡模式定义
    switch (idealState.getRebalanceMode()) {
    case FULL_AUTO:
      
      if (isMaintenanceModeEnabled) {
        //FULL_AUTO模式，并且启用了维护模式，使用MaintenanceRebalancer
        rebalancer = new MaintenanceRebalancer();
      } else {
      
        if (customizedRebalancer != null) {
          //FULL_AUTO模式，没有启用维护模式，有自定义的类，则使用自定义的类
          rebalancer = customizedRebalancer;
        } else {
          //FULL_AUTO模式，没有启用维护模式，有自定义的类，则使用自定义的类
          rebalancer = new AutoRebalancer();
        }
      }
      break;
    case SEMI_AUTO:
    
      //SEMI_AUTO，SemiAutoRebalancer
      rebalancer = new SemiAutoRebalancer<>();
      break;
    case CUSTOMIZED:
    
      //CUSTOMIZED，CustomRebalancer
      rebalancer = new CustomRebalancer();
      break;
    case USER_DEFINED:
    case TASK:
      //USER_DEFINED或者TASK。都是用用户自定义的
      rebalancer = customizedRebalancer;
      break;
    default:
      LogUtil.logError(logger, _eventId,
          "Fail to find the rebalancer, invalid rebalance mode " + idealState.getRebalanceMode());
      break;
    }

    return rebalancer;
  }

  //获取mapping计算器
  private MappingCalculator<ResourceControllerDataProvider> getMappingCalculator(
      Rebalancer<ResourceControllerDataProvider> rebalancer, String resourceName) {
    MappingCalculator<ResourceControllerDataProvider> mappingCalculator = null;

    if (rebalancer != null) {
      try {
        //将rebalancer进行强制转换，因为rebalancer都应该实现MappingCalculator接口
        mappingCalculator = MappingCalculator.class.cast(rebalancer);
      } catch (ClassCastException e) {
        LogUtil.logWarn(logger, _eventId,
            "Rebalancer does not have a mapping calculator, defaulting to SEMI_AUTO, resource: "
                + resourceName);
      }
    }
    //如果rebalancer没有实现，则自动使用SemiAutoRebalancer
    if (mappingCalculator == null) {
      mappingCalculator = new SemiAutoRebalancer<>();
    }

    return mappingCalculator;
  }
}
```

