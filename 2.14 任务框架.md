# 任务框架

helix中的任务框架，提供了执行任务调度和工作流管理。在helix中，有三层任务抽象提供给用户来定义依赖的逻辑。这个图展示了三层的关系。工作流可以包含很多任务job。job可以依赖于另一个，多个任务，包括不同分区的相同任务，可以被添加在一个任务中。任务框架不仅仅可以抽象3层任务逻辑，也能帮助执行任务分配和重平衡。用户可以在很早创建工作流（或者一个工作队列），然后任务可以添加到工作流中。这些任务包含了可执行的task任务，是由用户实现的。一旦工作流完成，helix将基于用户提供的条件调度工作。

![Task Framework flow chart](https://helix.apache.org/0.9.8-docs/images/TaskFrameworkLayers.png)

### Key Concepts 核心概念

- Task是基本的helix任务框架单元。可以代表单个可执行逻辑，是用户想要为每个分区（分布式单元）执行的
- Job定义了一个时间操作，覆盖了所有分区。它包含了多个任务，任务的配置，例如多少任务，每个任务的超时时间等等
- 工作流是方向性的，非循环的图，它代表了Job的关系，运行顺序，除此之外，工作流还可以提供自定义的配置，比如Job依赖关系
- Job队列是另外一种工作流。不同于一般的，Job队列将不会终止，除非被kill，队列也能够保持接受新来的任务。

### 实现任务

#### [Task Interface](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/Task.java) 任务接口

任务接口包含两个方法，run和cancel

用户可以实现自己的逻辑，在运行，或者取消/回滚等

```
public class MyTask implements Task {
  @Override
  TaskResult run() {
    // Task logic
  }
 
  @Override
  void cancel() {
    // Cancel logic
  }
}
```

#### [TaskConfig](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/TaskConfig.java) Task配置

在helix中，通常一个目标配置代表了目标的抽象，像TaskConfig, JobConfig and WorkflowConfig。TaskConfig包含了可配置的task条件。TaskConfig可以不需要任何输入来产生新的对象。

```
TaskConfig taskConfig = new TaskConfig(null, null, null, null);
```

For these four fields:

- Command: The task command, will use Job command if this is null。任务命令，如果没有，将使用Job命令
- ID: Task unique id, will generate a new ID for this task if input is null，唯一ID，如果没有，将生成新ID
- TaskTargetPartition: Target partition of a target. Could be null，目标分区
- ConfigMap: Task property key-value map containing all other property stated above, such as command, ID.配置map，task的属性，包含了所有其他属性。

#### 在Task和Job之间共享上下文

任务框架也提供给用户存储每个task、job、workflow数据的功能。上下文存储在工作流的层面，可被该工作流下的不同job共享。类似的，job层面的持久化会被job下的task共享。当前，用户可以扩展抽象类 [UserContentStore](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/UserContentStore.java) ，使用putUserContent and getUserContent方法。这与hashmap的put get类似，除了Scope，scope将会定义持久化的是哪一层。

```
public class MyTask extends UserContentStore implements Task {
  @Override
  TaskResult run() {
    putUserContent("KEY", "WORKFLOWVALUE", SCOPE.WORKFLOW);
    putUserContent("KEY", "JOBVALUE", SCOPE.JOB);
    putUserContent("KEY", "TASKVALUE", SCOPE.TASK);
    String taskValue = getUserContent("KEY", SCOPE.TASK);
  }
 ...
}
```

#### Return [Task Results](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/TaskResult.java) 返回任务结果

用户可以定义TaskResult，一旦task处于最终状态（完成/失败）。TaskResult包含两个字段：status和info。状态是当前的task状态-COMPLETED, CANCELLED, FAILED ， FATAL_FAILED。FAILED 和 FATAL_FAILED的不同在于task处于FATAL_FAILED时，helix不会重试任务，然后丢弃它。另外一个字段是信息，是字符串。用户可以定义任何信息如错误，描述等。

```
TaskResult run() {
    ....
    return new TaskResult(TaskResult.Status.FAILED, "ERROR MESSAGE OR OTHER INFORMATION");
}
```

#### 任务重试与丢弃

helix提供重试逻辑给用户，用户可以定义一个job下可以容忍多少次错误，这是下面job章节将会介绍的。另一个选择是提供给用户，如果用户认为task是非常关键的，并且在失败时不想进行重试，用户可以返回FATAL_FAILED状态的任务结果。然后helix将不会重试task。

```
return new TaskResult(TaskResult.Status.FATAL_FAILED, "DO NOT WANT TO RETRY, ERROR MESSAGE");
```

#### [TaskDriver](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java) 任务驱动

所有与工作流和job相关的控制操作都是基于TaskDriver，TaskDriver提供一些API来控制，修改，追踪task。这些API将会必要时在每个章节进行介绍。TaskDriver可以被 [HelixManager](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/HelixManager.java) or [ZkClient](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java) 来创建，使用集群的名称来创建。

```
HelixManager manager = new ZKHelixManager(CLUSTER_NAME, INSTANCE_NAME, InstanceType.PARTICIPANT, ZK_ADDRESS);
TaskDriver taskDriver1 = new TaskDriver(manager);
 
TaskDriver taskDriver2 = new TaskDriver(zkclient, CLUSTER_NAME);
```

#### 传播任务错误信息到helix

当任务进入错误时，他将通过TaskResult返回。不幸的是，用户不能直接获得这个。但是helix提供了错误信息的持久化。于是用户可以通过helix中的TaskDriver获取错误信息。错误信息将会被存储在每一个job的info字段。于是用户需要获取到JobContext，它有job状态和结果。

```
taskDriver.getJobContext("JOBNAME").getInfo();
```

### 创建工作流Workflow

#### 一次性工作流

通常，一次性工作流将会成为用户创建的默认工作流。首先需要使用工作流名称创建一个WorkflowConfig.Builder，然后所有的配置可以在builder设置，一旦配置完成， [WorkflowConfig](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/WorkflowConfig.java)可以获得，有两种规则来验证工作流配置。

- 过期时间不能小于0
- 计划配置应该有一次有效，或者是一个正的间隔值（周期性工作流）

Example:

```
Workflow.Builder myWorkflowBuilder = new Workflow.Builder("MyWorkflow");
myWorkflowBuilder.setExpiry(5000L);
Workflow myWorkflow = myWorkflowBuilder.build();
```

#### Recurrent Workflow 周期性工作流

周期性工作流是定期调度的，与一次性工作流不同的是需要设置一个周期[ScheduleConfig](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/ScheduleConfig.java). ScheduleConfig有两个方法，recurringFromNow 和 recurringFromDate。他们两个都需要recurUnit（递归的时间单位）和recurInteval（递归间隔的大小）。这是示例：

```
ScheduleConfig myConfig1 = ScheduleConfig.recurringFFromNow(TimeUnit.MINUTES, 5L);
ScheduleConfig myConfig2 = ScheduleConfig.recurringFFromDate(Calendar.getInstance.getTime, TimeUnit.HOURS, 10L);
```

当调度配置被创建，可以用在工作流的配置中

```
Workflow.Builder myWorkflowBuilder = new Workflow.Builder("MyWorkflow");
myWorkflowBuilder.setExpiry(2000L)
                 .setScheduleConfig(ScheduleConfig.recurringFromNow(TimeUnit.DAYS, 5));
Workflow myWorkflow = myWorkflowBuilder.build();
```

#### 启动工作流

启动工作流是使用taskdrive，因为这是一个异步调用，在开始工作流后，用户可以继续执行操作。

```
taskDriver.start(myWorkflow);
```

#### 停止工作流

通过TaskDriver停止:

```
taskDriver.stop(myWorkflow);
```

#### 恢复工作流

当工作流停止时，不意味着工作流没了，因为用户可以在工作流停止后恢复它：

```
taskDriver.resume(myWorkflow);
```

#### 删除工作流

Similar to start, stop and resume, delete operation is supported by TaskDriver.

```
taskDriver.delete(myWorkflow);
```

#### 添加Job

警告：Job仅仅可以被添加到WorkflowConfig.Builder，WorkflowConfig创建完成后，不可再添加job；如果你是创建job，需要看相关章节。

```
myWorkflowBuilder.addJob("JobName", jobConfigBuilder);
```

#### 添加Job依赖

Job可以有依赖。如果job2依赖job1，job1没有结束前，job2不会被调度。

```
myWorkflowBuilder.addParentChildDependency(ParentJobName, ChildJobName);
```

#### 调度工作流在将来时间执行

应用程序可以用ScheduleConfig创建工作流，以便在将来的时间执行

```
myWorkflowBuilder.setScheduleConfig(ScheduleConfig.oneTimeDelayedStart(new Date(inFiveSeconds)));
```

#### 其他工作流选项

| Additional Config Options                   | Detail                                                    |
| :------------------------------------------ | :-------------------------------------------------------- |
| *setJobDag(JobDag v)*                       | 如果用户已经定义job DAG，可以通过此方法设置               |
| *setExpiry(long v, TimeUnit unit)*          | 设置过期时间                                              |
| *setFailureThreshold(int failureThreshold)* | 设置失败阈值，当job失败达到此值，工作流失败               |
| *setWorkflowType(String workflowType)*      | 设置用户定义的工作流类型                                  |
| *setTerminable(boolean isTerminable)*       | 设置工作流是否可以终止                                    |
| *setCapacity(int capacity)*                 | 设置工作流可以持有的最大job数，只有工作流不可终止时使用。 |
| *setTargetState(TargetState v)*             | 设置工作流的最终状态                                      |

### 创建队列

[Job queue](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/JobQueue.java) job队列是另一种形式的工作流，以下是工作队列与工作流的不同：

| Property | Workflow                        | Job Queue                                 |
| :------- | :------------------------------ | :---------------------------------------- |
| 存活时间 | 工作流将在完成后删除            | job队列直到被删除都存在                   |
| 添加Job  | 一旦工作流构建完成，job不可添加 | 可以持续接受job                           |
| 并行执行 | 可以并行运行没有依赖的job       | 除非设置 *ParallelJobs*，否则不会并行执行 |

创建job队列，用户需要提供队列名称，工作流配置（前面）。与其他task类似，首先创建一个 JobQueue.Builder。然后job队列可被验证和生成。

```
WorkflowConfig.Builder myWorkflowCfgBuilder = new WorkflowConfig.Builder().setWorkFlowType("MyType");
JobQueue jobQueue = new JobQueue.Builder("MyQueueName").setWorkflowConfig(myWorkflowCfgBuilder.build()).build();
```

#### 追加Job到队列

警告：不同于 工作流，job队列上的job可以在任何时间添加，通过TaskDriver

```
jobQueueBuilder.enqueueJob("JobName", jobConfigBuilder);
```

#### 从队列中删除Job

helix允许用户从现有队列中删除job。TaskDriver中有API，删除job需要队列是停止的。删除成功再恢复job。

```
taskDriver.stop("QueueName");
taskDriver.deleteJob("QueueName", "JobName");
taskDriver.resume("QueueName");
```

#### 其他job队列的选项

*setParallelJobs(int parallelJobs)* : 设置可以并行运行的job数量，在job不存在依赖时。

### 创建Job

在生成[JobConfig](https://github.com/apache/helix/blob/helix-0.6.x/helix-core/src/main/java/org/apache/helix/task/JobConfig.java) 前，用户需要一个JobConfig.Builder

```
JobConfig.Builder myJobCfgBuilder = new JobConfig.Builder();
JobConfig myJobCfg = myJobCfgBuilder.build();
```

Helix有以下规则来验证job：

- 每个job必须有至少一个task
- task的超时时间不能小于0
- 每个实例的并发任务数不能小于1
- 每个task的最大尝试次数不能小于1
- 必须有工作流名称

#### 添加task

有两种方式

- 通过TaskConfig添加。用户可以创建一个TaskConfigs list或TaskConfigMap（taskid -> taskconfig）

```
TaskConfig taskCfg = new TaskConfig(null, null, null, null);
List<TaskConfig> taskCfgs = new ArrayList<TaskConfig>();
myJobCfg.addTaskConfigs(taskCfgs);
 
Map<String, TaskConfig> taskCfgMap = new HashMap<String, TaskConfig>();
taskCfgMap.put(taskCfg.getId(), taskCfg);
myJobCfg.addTaskConfigMap(taskCfgMap);
```

- 通过Job命令添加。如果用户不想指定每一个TaskConfig，可以创建相同的任务，通过制定job命令上的task数量

```
myJobCfg.setCommand("JobCommand").setNumberOfTasks(10);
```

警告：要么用户提供TaskConfigs / TaskConfigMap，要么提供Job命令和编号任务（“ Targeted Job”除外，请参阅以下部分）。否则，验证将失败。

#### 通用Job

通用job是创建的默认job，他没有目标资源。因此，通用job可以被分配给符合条件的实例。

#### 目标Job

目标Job设置目标资源。这种类型的job，job命令是必须的，但是任务数量不是必须的。task将依赖资源的分区数，为了设置目标资源，需要这样给JobConfig.Builder

```
myJobCfgBuilder.setTargetResource("TargetResourceName");
```

除此之外，用户可以设置实例的目标状态，比如，用户想要在master状态的实例上运行task，setTargetPartitionState可以帮助设置分区，到特定的实例上。

```
myJobCfgBuilder.setTargetPartitionState(Arrays.asList(new String[]{"Master", "Slave"}));
```

#### 实例组

支持使用目标实例组对job进行分组，用户首选需要定义实例组的标签，使用特定的标签去标记实例。然后可以将这些标签放入job，这些job仅仅想分配到这些实例。例如，用户数据仅仅在1，2，3节点可用。那么这三个节点可被标记CUSTOMER，然后用户数据相关的job可以设置实例组标签CUSTOMER，之后这些job被分配到1，2，3。为了添加实例组标签，只需要在JobConfig.Builder设置

```
jobCfg.setInstanceGroupTag("INSTANCEGROUPTAG");
```

#### 延迟调度job

Set up a schedule plan for the job. If both items are set, Helix will calculate and use the later one.

为job设置调度计划，如果这两个都设置了，helix将计算和使用后者。

```
myJobCfgBuilder.setExecutionDelay(delayMs);
myJobCfgBuilder.setExecutionStart(startTimeMs);
```

注意，调度的job需要是runnable，然后helix将会启动检查它的配置来进行调度。如果任何父job没有完成，那么job将不会调度即使调度时间已经过了。

#### 其他的Job选项

| Operation                                                    | Detail                                     |
| :----------------------------------------------------------- | :----------------------------------------- |
| *setWorkflow(String workflowName)*                           | 设置job所属的工作流                        |
| *setTargetPartions(List<String> targetPartionNames)*         | 设置分区的名称列表                         |
| *setTargetPartionStates(Set<String>)*                        | 设置分区状态                               |
| *setCommand(String command)*                                 | 设置job命令                                |
| *setJobCommandConfigMap(Map<String, String> v)*              | 设置job命令的配置map                       |
| *setTimeoutPerTask(long v)*                                  | 设置每个task的超时时间                     |
| *setNumConcurrentTasksPerInstance(int v)*                    | 设置任务可以在一个节点上并行执行的task数量 |
| *setMaxAttemptsPerTask(int v)*                               | 设置task的重试次数                         |
| *setFailureThreshold(int v)*                                 | 设置失败容忍                               |
| *setTaskRetryDelay(long v)*                                  | 设置task重试延迟                           |
| *setIgnoreDependentJobFailure(boolean ignoreDependentJobFailure)* | 设置时候忽略父job失败                      |
| *setJobType(String jobType)*                                 | 设置job类型                                |
| *setExecutionDelay(String delay)*                            | 设置延迟调度时间                           |
| *setExecutionStart(String start)*                            | 设置调度开始时间                           |

### 监控job的状态

我们在Workflow章节介绍了出色的TaskDriver工具，也有更多的方法提供给用户，用户可以同步等待job和工作流到达确定的状态，helix有pollForJobState 和 pollForWorkflowState API。pollForJobState包含以下参数

- 工作流名称，必填
- Job名称，必填
- 超时时间，非必填，默认3分钟，单位是毫秒
- TaskStates，至少一个状态，这个方法可以接受多个状态，直到这些状态中的一个到达，函数终止

For example:

```
taskDriver.pollForJobState("MyWorkflowName", "MyJobName", 180000L, TaskState.FAILED, TaskState.FATAL_FAILED);
taskDriver.pollForJobState("MyWorkflowName", "MyJobName", TaskState.COMPLETED);
```

pollForWorkflowState, 除了job名称外，参数都类似. For example:

```
taskDriver.pollForWorkflowState("MyWorkflowName", 180000L, TaskState.FAILED, TaskState.FATAL_FAILED);
taskDriver.pollForWorkflowState("MyWorkflowName", TaskState.COMPLETED);
```

#### 任务框架监控指标

Please refer to following links.

- [Job Monitor](https://helix.apache.org/0.9.8-docs/Metrics.html#MBean_JobMonitor)

- [Workflow Monitor](https://helix.apache.org/0.9.8-docs/Metrics.html#MBean_WorkflowMonitor)

  

# 用户定义task内容存储

用户定义的内容存储库的目的是为某些任务专用的元临时存储库提供易于使用的功能。在本章中，我们将学习如何在用户定义的任务中实现和使用内容存储。

## 内容存储实现

扩展抽象类UserContentStore

```
private static class ContentStoreTask extends UserContentStore implements Task {
  @Override public TaskResult run() {
    ...
  }
  @Override public void cancel() {
    ...
  }
}
```

默认的方法支持3种类型的域：

1. WORKFLOW 定义在工作流层面
2. JOB 定义在job层面
3. TASK 定义在TASK层面

## 内容存储用法

以下是在Task.run()方法访问内容存储

```
 private static class ContentStoreTask extends UserContentStore implements Task {
    @Override public TaskResult run() {
      // put values into the store
      putUserContent("ContentTest", "Value1", Scope.JOB);
      putUserContent("ContentTest", "Value2", Scope.WORKFLOW);
      putUserContent("ContentTest", "Value3", Scope.TASK);

      // get the values with the same key in the different scopes
      if (!getUserContent("ContentTest", Scope.JOB).equals("Value1") ||
          !getUserContent("ContentTest", Scope.WORKFLOW).equals("Value2") ||
          !getUserContent("ContentTest", Scope.TASK).equals("Value3")) {
        return new TaskResult(TaskResult.Status.FAILED, null);
      }

      return new TaskResult(TaskResult.Status.COMPLETED, null);
    }
  }
```

# 任务限速

在本章中，我们将学习如何在任务框架中控制任务的并行执行。

### 任务限制配置

Helix可以根据多个阈值控制并行执行的任务数。应用程序可以在以下配置项中设置这些阈值：

- JobConfig.ConcurrentTasksPerInstance允许在实例上运行的此作业中的并发任务数。
- InstanceConfig.MAX_CONCURRENT_TASK允许在实例上运行的并发任务总数。

另请参见[WorkflowConfig.ParallelJobs](http://helix.apache.org/0.9.8-docs/tutorial_task_framework.html)。

### 任务节流的工作优先级

每当根据阈值计划太多task时，Helix都会优先处理较旧的job。job的age是根据job开始时间计算的。

# 基于Quota的任务调度

## 介绍

![Intro](http://helix.apache.org/0.9.8-docs/images/quota_intro.png)

基于配额的任务调度是Helix Task Framework的一项功能新增功能，它使Task Framework的用户能够在分布式任务管理中应用类别的概念。

## 目的

随着Helix Task Framework在其他开放源代码框架（例如[Apache Gobblin](https://gobblin.apache.org/)和[Apache Pinot）中](http://pinot.incubator.apache.org/)得到越来越多的使用，它所管理的分布式任务的种类也越来越多。还向Helix提出了明确的功能请求，以通过创建相应的配额来区分不同类型的任务。

基于配额的任务调度旨在通过允许用户定义由配额类型及其相应配额组成的配额配置文件来满足这些请求。此功能的目标是三方面的：

1）用户将能够优先处理一种类型的工作流/作业/任务

2）实现任务类型之间的隔离

3）通过跟踪分布式状态来简化监视按类型执行。

## 词汇和定义

- Quota resource type: denotes a particular type of resource. Examples would be JVM thread count, memory, CPU resources, etc.. Generally, each task that runs on a Helix Participant (= instance, worker, node) occupies a set amount of resources. **Note that only JVM thread count is the only quota resource type currently supported by Task Framework, with each task occupying 1 thread out of 40 threads available per Helix Participant (instance).**
- Quota type: denotes which category a given job and its underlying tasks should be classified as. For example, you may define a quota configuration with two quota types, type “Backup”, and type “Aggregation” and a default type “DEFAULT”. You may prioritize the backup type by giving it a higher quota ratio - such as 20:10:10, respectively. When there are streams of jobs being submitted, you can expect each Participant, assuming that it has a total of 40 JVM threads, will have 20 “Backup” tasks, 10 “Aggregation” tasks, and 10 “DEFAULT” tasks. **Quota types are defined and applied at the job level, meaning all tasks belonging to a particular job with a quota type will be of that quota type.** Note that if a quota type is set for a workflow, then all jobs belonging to that workflow will *inherit* the type from the workflow.
- Quota: a number referring to a relative ratio that determines what portion of given resources should be allotted to a particular quota type.
  - E.g.) TYPE_0: 40, TYPE_1: 20, …, DEFAULT: 40
- Quota config: a set of string-integer mappings that indicate the quota resource type, quota types, and corresponding quotas. **Task Framework stores the quota config in ClusterConfig.**
- 任务框架：Apache Helix的组件。用户可以在其上以分布式方式定义和运行工作流，作业和任务的框架。
- 工作流：任务框架中最大的工作单元。工作流程由一个或多个作业组成。有两种类型的工作流：
  - 通用工作流程：通用工作流程是由用于一般目的的作业（作业DAG）组成的工作流程。**如果通用工作流程过期或超时，则可以将其删除。**
  - 作业队列：作业队列是一种特殊的工作流程类型，由往往具有线性相关性的作业组成（但是此相关性是可配置的）。**作业队列没有到期时间**-它一直存在直到被删除。
- 工作：任务框架中的第二大工作单元。一项工作包含一个或多个相互独立的任务。有两种类型的作业：
  - 通用作业：通用作业是由一个或多个任务组成的作业。
  - 目标作业：目标作业与常规作业的不同之处在于，这些作业必须具有*目标资源*，并且属于此类作业的任务将与目标资源的分区一起进行调度。为了说明这一点，Task Framework的Espresso用户可能希望在其一个名为*MemberDataDB的数据库*上安排备份作业。该数据库将被划分为多个分区（_MemberDataDB_1，_MemberDataDB *2，… \*MemberDataDB \*N）***，并假定已提交目标作业，因此其任务将与每个分区配对。此“配对”是必要的，因为此任务是一个备份任务，需要与该任务正在备份的分区位于同一台物理计算机上。
- 任务：任务框架中**最小的工作单元**。任务是一个独立的工作单元。
- 配额资源类型：表示一种特定的资源类型。示例包括JVM线程数，内存，CPU资源等。通常，在Helix参与者（=实例，工作程序，节点）上运行的每个任务占用一定数量的资源。**请注意，只有JVM线程计数是Task Framework当前支持的唯一配额资源类型，每个任务在每个Helix参与者（实例）可用的40个线程中占据1个线程。**
- 配额类型：表示给定工作及其基础任务应分类为哪个类别。例如，您可以使用两种配额类型定义配额配置，分别输入“ Backup”和“ Aggregation”以及默认类型“ DEFAULT”。您可以通过给备份类型更高的配额比率（例如分别为20:10:10）来对备份类型进行优先级排序。当有大量作业提交时，假设每个参与者共有40个JVM线程，它们将具有20个“备份”任务，10个“聚合”任务和10个“默认”任务。**配额类型是在作业级别定义和应用的，这意味着属于具有配额类型的特定作业的所有任务都将属于该配额类型。**请注意，如果为工作流程设置了配额类型，则属于该工作流程的所有作业都将*继承* 工作流程中的类型。
- 配额：表示相对比例的数字，该**比例**确定应将给定资源的哪一部分分配给特定的配额类型。
  - 例如：TYPE_0：40，TYPE_1：20，...，默认值：40
- 配额配置：一组字符串整数映射，指示配额资源类型，配额类型和相应的配额。**任务框架将配额配置存储在ClusterConfig中。**

## 架构

### AssignableInstance

AssignableInstance是一个抽象，代表每一个参与者，他们能够从Controller接受任务。每个AssignableInstance将缓存其正在运行的task以及基于配额的容量计算中的剩余task计数。

### AssignableInstanceManager

AssignableInstanceManager管理所有AssignableInstances。它也充当Controller和每个AssignableInstance之间的连接层。AssignableInstanceManager还提供了一组接口，这些接口使Controller可以轻松地确定AssignableInstance是否能够承担更多任务。

### TaskAssigner

TaskAssigner接口提供了基本API方法，这些方法涉及基于配额约束的任务分配。当前，任务框架仅涉及参与者端JVM线程的数量，每个线程对应于一个活动任务。

### RuntimeJobDag (JobDagIterator)

This new component serves as an iterator for JobDAGs for the Controller. Previously, task assignment required the Controller to iterate through all jobs and their underlying tasks to determine whether there were any tasks that needed to be assigned and scheduled. This proved to be inefficient and did not scale with the increasing load we were putting on Task Framework. Each RuntimeJobDag records states, that is, it knows what task needs to be offered up to the Controller for scheduling. This saves the redundant computation for the Controller every time it goes through the TaskSchedulingStage of the Task pipeline.

这个新组件充当Controller的JobDAG的迭代器。以前，任务分配要求Controller遍历所有作业及其基础任务，以确定是否有任何任务需要分配和安排。事实证明，这效率低下，并且无法随着我们在Task Framework上增加的负载而扩展。每个RuntimeJobDag都记录状态，即，它知道需要将哪些任务提供给Controller进行调度。每次通过任务管道的TaskSchedulingStage时，这都会为控制器节省冗余计算。

![Architecture](http://helix.apache.org/0.9.8-docs/images/quota_InstanceCapacityManager.jpeg)

## 用户手册

### 怎么工作

基于配额的任务调度的工作原理如下。如果设置了配额类型，则Task Framework将针对每种配额类型的所有配额配置号的总和计算比率。然后，它将应用该比率查找分配给每种配额类型的实际资源量。这是一个说明此情况的示例：假设配额配置如下：

```
"QUOTA_TYPES":{
  "A":"2"
  ,"B":"1"
  ,"DEFAULT":"1"
}
```

根据这些原始数字，任务框架将计算比率。使用比率，任务框架将应用比率来查找每种配额类型的实际资源量。下表总结了这些计算，**并假设每个实例有40个JVM线程**：

| Quota Type | Quota Config | Ratio | Actual Resource Allotted (# of JVM Threads) |
| :--------- | :----------- | :---- | :------------------------------------------ |
| A          | 2            | 50%   | 20                                          |
| B          | 1            | 25%   | 10                                          |
| DEFAULT    | 1            | 25%   | 10                                          |

每个实例（节点）将具有一个如下所示的配额配置文件。这有一些含义。首先，这允许**通过将大量资源分配给相应的配额类型来对某些作业**进行**优先级排序**。从这种意义上讲，您可以将配额配置编号/比率作为用户定义的优先级值。更具体地说，在上面的示例中使用配额配置文件。在这种情况下，如果每种配额类型都提交了100个作业，则类型A的作业将完成得更快；换句话说，由于连续的作业流，配额类型A的吞吐量将是其他配额类型的两倍，因此吞吐量将是其两倍。

基于配额的任务调度还允许**在调度作业中**进行**隔离/隔离**。假设有两类工作，第一类是短期的*紧急*工作，但需要立即运行。另一方面，假设第二类工作通常会花费更长的时间，但是它们并不那么紧迫，可能会花费一些时间。以前，这两种类型的作业将混合分配，安排和运行，确实很难确保紧急处理第一类作业。基于配额的调度通过允许用户创建对具有不同特征和要求的“类别”进行建模的配额类型来解决此问题。

### 如何使用

- 在ClusterConfig中设置配额配置

为了使用基于配额的任务计划，您必须首先建立一个配额配置。这是一次操作，一旦您确认ClusterConfig设置了配额配置，就无需再次设置它。例如，请参见以下代码片段：

```
ClusterConfig clusterConfig = _manager.getConfigAccessor().getClusterConfig(CLUSTER_NAME); // Retrieve ClusterConfig
clusterConfig.resetTaskQuotaRatioMap(); // 可选：您可能需要在创建新的配额配置之前重置配额配置
clusterConfig.setTaskQuotaRatio(DEFAULT_QUOTA_TYPE, 10); // 定义默认配额(DEFAULT_QUOTA_TYPE = "DEFAULT")
clusterConfig.setTaskQuotaRatio("A", 20); // Define quota type A
clusterConfig.setTaskQuotaRatio("B", 10); // Define quota type B
_manager.getConfigAccessor().setClusterConfig(CLUSTER_NAME, clusterConfig); //设置新的ClusterConfig
```

提醒您-如果您确实设置了配额配置，则**必须** **始终定义默认的配额类型（使用键“ DEFAULT”）**。否则，将不再计划和运行没有类型信息的作业。如果您在开始基于配额的调度之前一直使用Task Framework，则可能具有其工作没有设置任何类型的循环工作流。如果您忽略了默认配额类型，则这些循环工作流将无法正确执行。

在ClusterConfig中设置配额配置后，您将以JSON格式在ZooKeeper集群配置ZNode中看到更新的字段。请参见下面的示例：

```
{
  "id":"Example_Cluster"
  ,"simpleFields":{
    "allowParticipantAutoJoin":"true"
  }
  ,"listFields":{
  }
  ,"mapFields":{
    "QUOTA_TYPES":{
      "A":"20"
      ,"B":"10"
      ,"DEFAULT":"10"
    }
  }
}
```

- 设置工作流和作业的配额类型Builders for WorkflowConfig和JobConfig提供了一种用于设置作业的配额类型的方法。See below: 
- `java JobConfig.Builder jobBuilderA = new JobConfig.Builder().setCommand(JOB_COMMAND).setJobCommandConfigMap(_jobCommandMap) .addTaskConfigs(taskConfigsA).setNumConcurrentTasksPerInstance(50).setJobType("A"); // Setting the job quota type as "A" workflowBuilder.addJob("JOB_A", jobBuilderA);`

## FAQ

- 如果我没有在ClusterConfig中设置配额配置会怎样？
  - 当在ClusterConfig中找不到配额配置时，任务框架会将所有传入的作业视为DEFAULT，并将100％的配额资源提供给默认类型。
- 如果我的工作没有设置配额类型会怎样？
  - 如果Task Framework遇到没有配额类型的作业（即，quotaType字段丢失，为空字符串或文字为“ null”），则该作业将被视为DEFAULT作业。
- 如果在ClusterConfig中的配额配置中不存在配额类型的工作流程/作业，该怎么办？
  - Task Framework将**无法**找到正确的配额类型，因此会将**其视为DEFAULT类型**，并将使用DEFAULT类型的配额进行分配和安排。
- 那有针对性的工作呢？
  - 配额还将应用于目标作业，目标作业的每个任务占用预设的资源量（当前，每个任务占用1个JVM线程）。
- 那工作队列呢？
  - 基于配额的调度适用于所有类型的工作流程-通用工作流程和作业队列。请用户注意，要始终检查作业的配额类型是否已正确设置。Task Framework**不会**自动删除由于配额类型无效而被卡住的作业，也**不会**通知用户，因此我们提醒所有用户通过查询ClusterConfig中的设置来确保配额类型存在。

## 未来规划

基于配额的任务调度已在LinkedIn上进行了内部测试，并已集成到[Apache Gobblin中](https://gobblin.apache.org/)，使Helix Task Framework和Gobblin的Job Launcher的用户可以定义类别和相应的配额值。有一些立即要做的事情可以改善此功能的可用性：

- 更细粒度的配额配置文件

当前，配额配置文件适用于整个集群。也就是说，在ClusterConfig中定义的一个配额配置文件将全局应用于所有参与者。但是，某些用例可能要求每个参与者具有不同的配额配置文件。

- 使参与者的最大JVM线程容量可配置

Helix Task Framework的最大任务线程数设置为40。使之可配置将可能使某些用户根据此类任务的执行时间来增加任务的吞吐量。

- 为配额资源类型添加更多维度

当前，每个参与者的JVM线程数是Helix Task Framework定义配额的唯一维度。但是，如前面各节所述，这可以扩展到诸如CPU使用率，内存使用率或磁盘使用率之类的常用约束。随着新维度的添加，将需要TaskAssigner接口的其他实现，该接口根据约束为任务生成任务。