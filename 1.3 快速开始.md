## 快速开始

## 获取 Helix

首先，让我们得到Helix。要么构建它，要么下载它。

### Build

```
git clone https://git-wip-us.apache.org/repos/asf/helix.git
cd helix
git checkout tags/helix-0.9.8
mvn install package -DskipTests
cd helix-core/target/helix-core-pkg/bin # This folder contains all the scripts used in following sections
chmod +x *
```

### Download

Download the 0.9.8 release package [here](http://helix.apache.org/0.9.8-docs/download.html)

## 概述

在本快速入门中，我们将建立一个主从复制（master-slave replicated）的分区系统。然后，我们将演示如何添加节点，重新平衡分区，并展示Helix如何管理故障转移。

## Let's Do It

Helix提供了命令行界面来设置集群并查看集群状态。了解Helix如何看待集群的最好方法是构建集群。

### 进入工具目录

如果您构建了代码：

```
cd helix/helix/helix-core/target/helix-core-pkg/bin
```

如果您下载了发行包，请解压缩它。

## 精简版

您可以在此演示中观察组件的协同工作，该演示将执行以下操作：

- 创建集群
- 将2个节点（参与者）添加到集群
- 设置具有6个分区和2个副本的资源：每个分区有1个Master，1个Slave
- 在Helix平衡分区后显示群集状态
- 添加第三个节点
- 显示集群状态。请注意，第三个节点已掌握2个分区的权限。
- Kill第三个节点（Helix负责故障转移）
- 显示集群状态。请注意，两个尚存的节点将从发生故障的节点接管分区的主控权

### 运行 Demo

```
cd helix/helix/helix-core/target/helix-core-pkg/bin
./quickstart.sh
```

#### 初始设置

设置了2个节点，并重新分配了分区。

群集状态如下：

```
CLUSTER STATE: After starting 2 nodes
                localhost_12000    localhost_12001
MyResource_0           M                  S
MyResource_1           S                  M
MyResource_2           M                  S
MyResource_3           M                  S
MyResource_4           S                  M
MyResource_5           S                  M
```

请注意，每个分区有一个master和一个slave。

#### 添加节点

添加第三个节点，并重新平衡群集。

群集状态更改为：

```
CLUSTER STATE: After adding a third node
               localhost_12000    localhost_12001    localhost_12002
MyResource_0          S                  M                  S
MyResource_1          S                  S                  M
MyResource_2          M                  S                  S
MyResource_3          S                  S                  M
MyResource_4          M                  S                  S
MyResource_5          S                  M                  S
```

请注意，每个分区有一个master和**两个**slave。这是可以预期的，因为有三个节点。

#### Kill 节点

最后，杀死一个节点以模拟故障

Helix确保每个分区都有一个master。群集状态更改为：

```
CLUSTER STATE: After the 3rd node stops/crashes
               localhost_12000    localhost_12001    localhost_12002
MyResource_0          S                  M                  -
MyResource_1          S                  M                  -
MyResource_2          M                  S                  -
MyResource_3          M                  S                  -
MyResource_4          M                  S                  -
MyResource_5          S                  M                  -
```

## 详细版本

现在，您可以手动运行相同的步骤。在此详细版本中，我们将执行以下操作：

- 定义集群
- 将两个节点添加到集群
- 添加一个具有6个分区的资源，每个分区具有1个主副本和2个从副本
- 验证集群运行状况是否良好，并检查Helix视图
- 扩展集群：添加一些节点并重新平衡分区
- 故障转移：停止节点并验证主控权转移

### 安装并启动ZooKeeper

Zookeeper可以以独立模式或复制模式启动。

有关更多信息，请访问：

- http://zookeeper.apache.org/doc/r3.3.3/zookeeperStarted.html
- http://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_zkMulitServerSetup

在此示例中，让我们以本地模式启动zookeeper。

#### 在端口2199上本地启动ZooKeeper

```
./start-standalone-zookeeper.sh 2199 &
```

### 定义集群

helix-admin工具用于集群管理任务。在快速入门中，我们将使用命令行界面。Helix也支持REST接口。

zookeeper_address 的格式为 host:port 例如对于独立服务器 localhost:2199 对于多节点，则为 host1:port,host2:port 

接下来，我们将使用以下属性设置集群MYCLUSTER集群：

- 3个实例在localhost端口12913,12914,12915上运行
- 一个名为myDB的数据库，具有6个分区
- 每个分区将具有3个副本，其中1个为主副本，2个从属副本
- ZooKeeper在本地主机本地运行：2199

#### 创建集群MYCLUSTER

```
# ./helix-admin.sh --zkSvr <zk_address> --addCluster <clustername>
./helix-admin.sh --zkSvr localhost:2199 --addCluster MYCLUSTER
```

### 将节点添加到群集

在这种情况下，我们将添加三个节点： localhost:12913, localhost:12914, localhost:12915

```
# helix-admin.sh --zkSvr <zk_address>  --addNode <clustername> <host:port>
./helix-admin.sh --zkSvr localhost:2199  --addNode MYCLUSTER localhost:12913
./helix-admin.sh --zkSvr localhost:2199  --addNode MYCLUSTER localhost:12914
./helix-admin.sh --zkSvr localhost:2199  --addNode MYCLUSTER localhost:12915
```

### 定义资源和分区

在此示例中，资源是数据库，分为6种方式。请注意，在生产系统中，通常会进行过度分区以实现更好的负载平衡。Helix已在生产中用于管理数百个数据库，每个数据库都在10s的物理节点上运行10s或100s的分区。

#### 使用MasterSlave状态模型创建具有6个分区的数据库

Helix确保每个分区上只有一个master。

```
# helix-admin.sh --zkSvr <zk_address> --addResource <clustername> <resourceName> <numPartitions> <StateModelName>
./helix-admin.sh --zkSvr localhost:2199 --addResource MYCLUSTER myDB 6 MasterSlave
```

#### 让Helix为节点分配分区

此命令将在群集中的所有节点之间分配分区。在此示例中，每个分区具有3个副本。

```
# helix-admin.sh --zkSvr <zk_address> --rebalance <clustername> <resourceName> <replication factor>
./helix-admin.sh --zkSvr localhost:2199 --rebalance MYCLUSTER myDB 3
```

现在，在ZooKeeper中定义了集群。节点（localhost：12913，localhost：12914，localhost：12915）和资源（myDB，使用MasterSlave模型具有6个分区）都已正确配置。并假设复制因子为3，计算了*IdealState*。

### 启动Helix控制器

现在，在ZooKeeper中定义了集群，Helix控制器可以管理集群了。

```
# Start the cluster manager, which will manage MYCLUSTER
./run-helix-controller.sh --zkSvr localhost:2199 --cluster MYCLUSTER 2>&1 > /tmp/controller.log &
```

### 启动要管理的群集

我们已经启动了ZooKeeper，定义了集群，资源，分区，并启动了Helix控制器。接下来，我们将启动要管理的系统的节点。每个节点都是一个参与者，这是要管理的系统组件的实例。Helix将工作分配给参与者，跟踪其角色和健康状况，并在节点发生故障时采取措施。

```
# start up each instance.  These are mock implementations that are actively managed by Helix
./start-helix-participant.sh --zkSvr localhost:2199 --cluster MYCLUSTER --host localhost --port 12913 --stateModelType MasterSlave 2>&1 > /tmp/participant_12913.log
./start-helix-participant.sh --zkSvr localhost:2199 --cluster MYCLUSTER --host localhost --port 12914 --stateModelType MasterSlave 2>&1 > /tmp/participant_12914.log
./start-helix-participant.sh --zkSvr localhost:2199 --cluster MYCLUSTER --host localhost --port 12915 --stateModelType MasterSlave 2>&1 > /tmp/participant_12915.log
```

### 检查集群

现在，让我们看一下集群的Helix视图。我们将按照以下方式进行工作：

```
Clusters -> MYCLUSTER -> instances -> instance detail
                      -> resources -> resource detail
                      -> partitions
```

单个Helix控制器可以管理多个集群，尽管到目前为止，我们仅定义了一个集群。让我们来看看：

```
# List existing clusters
./helix-admin.sh --zkSvr localhost:2199 --listClusters

Existing clusters:
MYCLUSTER
```

现在，让我们看看MYCLUSTER的Helix视图：

```
# helix-admin.sh --zkSvr <zk_address> --listClusterInfo <clusterName>
./helix-admin.sh --zkSvr localhost:2199 --listClusterInfo MYCLUSTER

Existing resources in cluster MYCLUSTER:
myDB
Instances in cluster MYCLUSTER:
localhost_12915
localhost_12914
localhost_12913
```

让我们看一下实例的详细信息：

```
# ./helix-admin.sh --zkSvr <zk_address> --listInstanceInfo <clusterName> <InstanceName>
./helix-admin.sh --zkSvr localhost:2199 --listInstanceInfo MYCLUSTER localhost_12913

InstanceConfig: {
  "id" : "localhost_12913",
  "mapFields" : {
  },
  "listFields" : {
  },
  "simpleFields" : {
    "HELIX_ENABLED" : "true",
    "HELIX_HOST" : "localhost",
    "HELIX_PORT" : "12913"
  }
}
```

#### 查询资源信息

```
# helix-admin.sh --zkSvr <zk_address> --listResourceInfo <clusterName> <resourceName>
./helix-admin.sh --zkSvr localhost:2199 --listResourceInfo MYCLUSTER myDB

IdealState for myDB:
{
  "id" : "myDB",
  "mapFields" : {
    "myDB_0" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    },
    "myDB_1" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "MASTER"
    },
    "myDB_2" : {
      "localhost_12913" : "MASTER",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "SLAVE"
    },
    "myDB_3" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "MASTER"
    },
    "myDB_4" : {
      "localhost_12913" : "MASTER",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "SLAVE"
    },
    "myDB_5" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    }
  },
  "listFields" : {
    "myDB_0" : [ "localhost_12914", "localhost_12913", "localhost_12915" ],
    "myDB_1" : [ "localhost_12915", "localhost_12913", "localhost_12914" ],
    "myDB_2" : [ "localhost_12913", "localhost_12915", "localhost_12914" ],
    "myDB_3" : [ "localhost_12915", "localhost_12913", "localhost_12914" ],
    "myDB_4" : [ "localhost_12913", "localhost_12914", "localhost_12915" ],
    "myDB_5" : [ "localhost_12914", "localhost_12915", "localhost_12913" ]
  },
  "simpleFields" : {
    "IDEAL_STATE_MODE" : "AUTO",
    "REBALANCE_MODE" : "SEMI_AUTO",
    "NUM_PARTITIONS" : "6",
    "REPLICAS" : "3",
    "STATE_MODEL_DEF_REF" : "MasterSlave",
    "STATE_MODEL_FACTORY_NAME" : "DEFAULT"
  }
}

ExternalView for myDB:
{
  "id" : "myDB",
  "mapFields" : {
    "myDB_0" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    },
    "myDB_1" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "MASTER"
    },
    "myDB_2" : {
      "localhost_12913" : "MASTER",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "SLAVE"
    },
    "myDB_3" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "MASTER"
    },
    "myDB_4" : {
      "localhost_12913" : "MASTER",
      "localhost_12914" : "SLAVE",
      "localhost_12915" : "SLAVE"
    },
    "myDB_5" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    }
  },
  "listFields" : {
  },
  "simpleFields" : {
    "BUCKET_SIZE" : "0"
  }
}
```

现在，让我们看一下其中一个分区：

```
# helix-admin.sh --zkSvr <zk_address> --listResourceInfo <clusterName> <partition>
./helix-admin.sh --zkSvr localhost:2199 --listResourceInfo mycluster myDB_0
```

### 扩展集群

接下来，我们将展示Helix如何完成您原本必须构建到系统中的工作。当您向集群添加容量时，您希望工作被平均分配。在此示例中，我们从3个节点开始，有6个分区。分区均匀平衡，每个节点2个主节点和4个从节点。我们再添加3个节点：localhost：12916，localhost：12917，localhost：12918

```
./helix-admin.sh --zkSvr localhost:2199  --addNode MYCLUSTER localhost:12916
./helix-admin.sh --zkSvr localhost:2199  --addNode MYCLUSTER localhost:12917
./helix-admin.sh --zkSvr localhost:2199  --addNode MYCLUSTER localhost:12918
```

并启动以下实例：

```
# start up each instance.  These are mock implementations that are actively managed by Helix
./start-helix-participant.sh --zkSvr localhost:2199 --cluster MYCLUSTER --host localhost --port 12916 --stateModelType MasterSlave 2>&1 > /tmp/participant_12916.log
./start-helix-participant.sh --zkSvr localhost:2199 --cluster MYCLUSTER --host localhost --port 12917 --stateModelType MasterSlave 2>&1 > /tmp/participant_12917.log
./start-helix-participant.sh --zkSvr localhost:2199 --cluster MYCLUSTER --host localhost --port 12918 --stateModelType MasterSlave 2>&1 > /tmp/participant_12918.log
```

现在，让Helix为您完成工作。要转移工作，只需重新平衡即可。重新平衡后，每个节点将有一个主节点和两个从节点。

```
./helix-admin.sh --zkSvr localhost:2199 --rebalance MYCLUSTER myDB 3
```

### View the Cluster

好，让我们看看它

```
./helix-admin.sh --zkSvr localhost:2199 --listResourceInfo MYCLUSTER myDB

IdealState for myDB:
{
  "id" : "myDB",
  "mapFields" : {
    "myDB_0" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12917" : "MASTER"
    },
    "myDB_1" : {
      "localhost_12916" : "SLAVE",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "MASTER"
    },
    "myDB_2" : {
      "localhost_12913" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_3" : {
      "localhost_12915" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_4" : {
      "localhost_12916" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_5" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    }
  },
  "listFields" : {
    "myDB_0" : [ "localhost_12917", "localhost_12913", "localhost_12914" ],
    "myDB_1" : [ "localhost_12918", "localhost_12917", "localhost_12916" ],
    "myDB_2" : [ "localhost_12913", "localhost_12917", "localhost_12918" ],
    "myDB_3" : [ "localhost_12915", "localhost_12917", "localhost_12918" ],
    "myDB_4" : [ "localhost_12916", "localhost_12917", "localhost_12918" ],
    "myDB_5" : [ "localhost_12914", "localhost_12915", "localhost_12913" ]
  },
  "simpleFields" : {
    "IDEAL_STATE_MODE" : "AUTO",
    "REBALANCE_MODE" : "SEMI_AUTO",
    "NUM_PARTITIONS" : "6",
    "REPLICAS" : "3",
    "STATE_MODEL_DEF_REF" : "MasterSlave",
    "STATE_MODEL_FACTORY_NAME" : "DEFAULT"
  }
}

ExternalView for myDB:
{
  "id" : "myDB",
  "mapFields" : {
    "myDB_0" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12917" : "MASTER"
    },
    "myDB_1" : {
      "localhost_12916" : "SLAVE",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "MASTER"
    },
    "myDB_2" : {
      "localhost_12913" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_3" : {
      "localhost_12915" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_4" : {
      "localhost_12916" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_5" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    }
  },
  "listFields" : {
  },
  "simpleFields" : {
    "BUCKET_SIZE" : "0"
  }
}
```

任务完成。分区很好地平衡了。

### 故障转移如何？

构建容错系统并不是一件容易的事，但是使用Helix，这很容易。Helix检测到故障实例，并自动触发主控权转移。

首先，让一个实例失败。在此示例中，我们将杀死localhost：12918以模拟失败。

我们丢失了localhost：12918，因此myDB_1丢失了其MASTER。Helix可以解决此问题，它将把主控权转移到当前为SLAVE的运行状况良好的节点，例如localhost：12197。假设5个节点上有6个分区，Helix会尽最大可能平衡负载。让我们来看看：

```
./helix-admin.sh --zkSvr localhost:2199 --listResourceInfo MYCLUSTER myDB

IdealState for myDB:
{
  "id" : "myDB",
  "mapFields" : {
    "myDB_0" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12917" : "MASTER"
    },
    "myDB_1" : {
      "localhost_12916" : "SLAVE",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "MASTER"
    },
    "myDB_2" : {
      "localhost_12913" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_3" : {
      "localhost_12915" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_4" : {
      "localhost_12916" : "MASTER",
      "localhost_12917" : "SLAVE",
      "localhost_12918" : "SLAVE"
    },
    "myDB_5" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    }
  },
  "listFields" : {
    "myDB_0" : [ "localhost_12917", "localhost_12913", "localhost_12914" ],
    "myDB_1" : [ "localhost_12918", "localhost_12917", "localhost_12916" ],
    "myDB_2" : [ "localhost_12913", "localhost_12918", "localhost_12917" ],
    "myDB_3" : [ "localhost_12915", "localhost_12918", "localhost_12917" ],
    "myDB_4" : [ "localhost_12916", "localhost_12917", "localhost_12918" ],
    "myDB_5" : [ "localhost_12914", "localhost_12915", "localhost_12913" ]
  },
  "simpleFields" : {
    "IDEAL_STATE_MODE" : "AUTO",
    "REBALANCE_MODE" : "SEMI_AUTO",
    "NUM_PARTITIONS" : "6",
    "REPLICAS" : "3",
    "STATE_MODEL_DEF_REF" : "MasterSlave",
    "STATE_MODEL_FACTORY_NAME" : "DEFAULT"
  }
}

ExternalView for myDB:
{
  "id" : "myDB",
  "mapFields" : {
    "myDB_0" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "SLAVE",
      "localhost_12917" : "MASTER"
    },
    "myDB_1" : {
      "localhost_12916" : "SLAVE",
      "localhost_12917" : "MASTER"
    },
    "myDB_2" : {
      "localhost_12913" : "MASTER",
      "localhost_12917" : "SLAVE"
    },
    "myDB_3" : {
      "localhost_12915" : "MASTER",
      "localhost_12917" : "SLAVE"
    },
    "myDB_4" : {
      "localhost_12916" : "MASTER",
      "localhost_12917" : "SLAVE"
    },
    "myDB_5" : {
      "localhost_12913" : "SLAVE",
      "localhost_12914" : "MASTER",
      "localhost_12915" : "SLAVE"
    }
  },
  "listFields" : {
  },
  "simpleFields" : {
    "BUCKET_SIZE" : "0"
  }
}
```

正如我们在本快速入门中所见，Helix负责分区，负载平衡，弹性，故障检测和恢复。

### ZooInspector

您可以直接转到zookeeper，以查看所有基础数据。使用zookeeper随附的ZooInspector浏览数据。这是一个Java小程序（确保您有X窗口）

要启动zooinspector，请从<zk_install_directory>/contrib/ZooInspector运行以下命令

```
java -cp zookeeper-3.3.3-ZooInspector.jar:lib/jtoaster-1.0.4.jar:../../lib/log4j-1.2.15.jar:../../zookeeper-3.3.3.jar org.apache.zookeeper.inspector.ZooInspector
```

### 下一步

现在您已经了解了Helix的概念，请阅读该[教程，](http://helix.apache.org/0.9.8-docs/Tutorial.html)以了解如何为系统选择正确的状态模型和约束以及如何实现它。在许多情况下，内置功能都可以满足您的要求。最重要的是，Helix是一个可自定义的框架，因此您可以插入自己的行为，同时保留Helix提供的自动化。